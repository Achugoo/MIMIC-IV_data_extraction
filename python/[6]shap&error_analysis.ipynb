{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984b565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import pickle\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, brier_score_loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edafeb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "gamma = 1\n",
    "batch_size = 256\n",
    "seq_len = 1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "max_epoch = 100\n",
    "experiment_time = 5\n",
    "limit_early_stop_count = 5\n",
    "\n",
    "show_shap_flag = True\n",
    "select_feature_flag = False\n",
    "use_upsample = False\n",
    "use_mini_feature = False\n",
    "only_Weaning = False\n",
    "\n",
    "task_name_list = ['Weaning_successful']\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786bc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_MTL(nn.Module):\n",
    "    def __init__(self, input_dim, task_name_list, dropout_ratio=0.0):\n",
    "        super(MLP_MTL, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        self.relu = nn.ReLU()  # Activation function for hidden layers\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.task_name_list = task_name_list\n",
    "        self.num_tasks = len(task_name_list)\n",
    "        hidden_dim = [256, 128, 64, 32]\n",
    "        output_size = 1\n",
    "\n",
    "        # Bottom\n",
    "        self.bt_fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
    "        self.bt_fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "        self.bt_fc3 = nn.Linear(hidden_dim[1], hidden_dim[2])\n",
    "\n",
    "        # Towers\n",
    "        self.task_fc0 = nn.ModuleList([nn.Linear(hidden_dim[2], hidden_dim[3]) for _ in range(self.num_tasks)])\n",
    "        self.task_fc1 = nn.ModuleList([nn.Linear(hidden_dim[3], output_size) for _ in range(self.num_tasks)])\n",
    "    \n",
    "    def data_check(self,x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        if x.ndim == 3:\n",
    "            x = x.reshape(x.shape[0], x.shape[1] * x.shape[2])  # Flatten \n",
    "            \n",
    "        x = x.to(device)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.data_check(x)\n",
    "\n",
    "        # Bottom\n",
    "        x = self.bt_fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bt_fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bt_fc3(x)\n",
    "        h = self.relu(x)\n",
    "        h = self.dropout(h)  \n",
    "\n",
    "        # Towers\n",
    "        task_out = {}\n",
    "        for task_index in range(self.num_tasks):\n",
    "            task_name = self.task_name_list[task_index]\n",
    "            hi = self.task_fc0[task_index](h)\n",
    "            hi = self.relu(hi)\n",
    "            hi = self.dropout(hi)\n",
    "            hi = self.task_fc1[task_index](hi)\n",
    "            hi = self.sigmoid(hi)\n",
    "            task_out[task_name] = hi    \n",
    "            \n",
    "        if len(self.task_name_list) == 1:\n",
    "            return task_out[self.task_name_list[0]]\n",
    "        else:\n",
    "            return task_out\n",
    "    \n",
    "    def predict_prob(self, x):\n",
    "        self.eval()\n",
    "        prob_dict = self.forward(x)\n",
    "        \n",
    "        if len(self.task_name_list) == 1:\n",
    "            prob_dict_true = {}\n",
    "            prob_dict_true[self.task_name_list[0]] = prob_dict\n",
    "            return prob_dict_true\n",
    "        return prob_dict\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        self.eval()\n",
    "        prob_dict = self.forward(x)\n",
    "        \n",
    "        if len(self.task_name_list) == 1:\n",
    "            prob_dict_true = {}\n",
    "            prob_dict_true[self.task_name_list[0]] = prob_dict\n",
    "            return prob_dict_true\n",
    "        \n",
    "        return prob_dict\n",
    "    \n",
    "    def predict(self, x, threshold = 0.5):\n",
    "        self.eval()\n",
    "        prob_dict = self.predict_prob(x)\n",
    "        pred_dict = {}\n",
    "        \n",
    "        for key, value in prob_dict.items():\n",
    "            #tensor轉numpy\n",
    "            value = value.cpu().detach().numpy()\n",
    "            pred_class = [1 if x > threshold else 0 for x in value]\n",
    "            pred_dict[key] = np.array(pred_class) \n",
    "        return pred_dict\n",
    "    \n",
    "    def evaluate(self,X,label,task_name,criterion):\n",
    "        with torch.no_grad():\n",
    "            prob = self.predict_prob(X)[task_name].cpu().detach().numpy() #tensor=>numpy\n",
    "            pred = self.predict(X)[task_name] \n",
    "            score = compute_scores(label,pred,prob)\n",
    "            score['task'] = task_name\n",
    "            loss = criterion(torch.from_numpy(prob).to(device),torch.from_numpy(label).to(device)).item()\n",
    "            score['loss'] = loss/len(label)\n",
    "            return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8537c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(y_true, y_pred,y_prob):\n",
    "    if np.any(np.isnan(y_prob)):\n",
    "        print(y_prob)\n",
    "        input()\n",
    "        \n",
    "    scores = {}\n",
    "    try:\n",
    "        scores['task'] = 'Null'\n",
    "        scores['auroc'] = round(roc_auc_score(y_true, y_prob), 3)\n",
    "        scores['acc'] = round(accuracy_score(y_true, y_pred), 3)\n",
    "        scores['f1'] = round(f1_score(y_true, y_pred), 3)\n",
    "        scores['pre'] = round(precision_score(y_true, y_pred), 3)\n",
    "        scores['recall'] = round(recall_score(y_true, y_pred), 3)\n",
    "        scores['brier_score'] = round(brier_score_loss(y_true, y_prob), 3)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8daed213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    model\n",
    "    dict: Mydataset\n",
    "    loss_function\n",
    "Output:\n",
    "    score: dict + dict\n",
    "    result: dict => ['total_auc','total_loss']\n",
    "\"\"\"\n",
    "def test(model, dataset_dict, criterion, is_show = True , only_Weaning = False):\n",
    "    model.eval()\n",
    "\n",
    "    task_name_list = list(dataset_dict.keys())\n",
    "    score = {}\n",
    "    result = {'total_auc': 0, 'total_loss': 0}\n",
    "    for task_name in task_name_list:  # 循環每個任務\n",
    "        X = dataset_dict[task_name].inputs.numpy()\n",
    "        Y = dataset_dict[task_name].labels.unsqueeze(1).numpy()\n",
    "    \n",
    "        score[task_name] = model.evaluate(X,Y,task_name,criterion)\n",
    "        \n",
    "        if only_Weaning == True and 'Weaning_succecssful' in task_name_list:\n",
    "            if task_name == 'Weaning_succecssful':\n",
    "                result['total_auc'] = result['total_auc'] + score[task_name]['auroc']\n",
    "                result['total_loss'] = result['total_loss'] + score[task_name]['loss']\n",
    "        else:\n",
    "            result['total_auc'] = result['total_auc'] + score[task_name]['auroc']\n",
    "            result['total_loss'] = result['total_loss'] + score[task_name]['loss']\n",
    "            \n",
    "        if is_show:\n",
    "            print(score[task_name])\n",
    "    \n",
    "    return score,result\n",
    "\n",
    "\"\"\"\n",
    "local_best_model_dict: #dict{'task_name':{'model','performance(target_score)','id'}}\n",
    "model\n",
    "\"\"\"\n",
    "def test2(local_best_model_dict, modelr, dataset_dict, criterion, is_show = True):\n",
    "    score = {}\n",
    "    result = {'total_auc': 0, 'total_loss': 0}\n",
    "    task_name_list = list(dataset_dict.keys())\n",
    "    \n",
    "    for task_name in task_name_list:\n",
    "        print(f\"task: {task_name} \")\n",
    "        print(f\"{local_best_model_dict[task_name]['performance']}\")\n",
    "        modelr.load_state_dict(local_best_model_dict[task_name]['model'])\n",
    "        modelr.eval()\n",
    "        X = dataset_dict[task_name].inputs.numpy()\n",
    "        Y = dataset_dict[task_name].labels.unsqueeze(1).numpy()\n",
    "        score[task_name] = modelr.evaluate(X,Y,task_name,criterion)\n",
    "        result['total_auc'] = result['total_auc'] + score[task_name]['auroc']\n",
    "        result['total_loss'] = result['total_loss'] + score[task_name]['loss']\n",
    "        if is_show:\n",
    "            print(score[task_name])\n",
    "            \n",
    "    return score,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d074fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, np_X_scalar,np_X_original, np_Y):\n",
    "        self.inputs = torch.from_numpy(np_X_scalar).float()\n",
    "        self.inputs_original = torch.from_numpy(np_X_original).float()\n",
    "        self.labels = torch.from_numpy(np_Y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "    \n",
    "    def remove_samples(self, feature_index, threshold, condition_type):\n",
    "        \"\"\"\n",
    "        Remove samples based on a specified condition on a specific feature.\n",
    "\n",
    "        Parameters:\n",
    "        - feature_index (int): Index of the feature.\n",
    "        - threshold (float): Threshold value for the condition.\n",
    "        - condition_type (str): Type of condition ('type1' for '<' or 'type2' for '>=').\n",
    "        \"\"\"\n",
    "        if condition_type == 'type1':\n",
    "            indices_to_remove = torch.nonzero(self.inputs[:, feature_index] < threshold).squeeze()\n",
    "        elif condition_type == 'type2':\n",
    "            indices_to_remove = torch.nonzero(self.inputs[:, feature_index] >= threshold).squeeze()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid condition_type. Use 'type1' for '<' or 'type2' for '>='.\")\n",
    "\n",
    "        # Remove samples\n",
    "        self.inputs = torch.index_select(self.inputs, 0, indices_to_remove)\n",
    "        self.inputs_original = torch.index_select(self.inputs_original, 0, indices_to_remove)\n",
    "        self.labels = torch.index_select(self.labels, 0, indices_to_remove)\n",
    "    \n",
    "class BCEFocalLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=2, alpha=0.25, reduction='elementwise_mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    " \n",
    "    def forward(self, _input, target):\n",
    "        pt = _input\n",
    "        alpha = self.alpha\n",
    "        loss = - alpha * (1 - pt) ** self.gamma * target * torch.log(pt) - \\\n",
    "               (1 - alpha) * pt ** self.gamma * (1 - target) * torch.log(1 - pt)\n",
    "        if self.reduction == 'elementwise_mean':\n",
    "            loss = torch.mean(loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = torch.sum(loss)\n",
    "        return loss    \n",
    "\n",
    "    \n",
    "def check_label_distribution (data_Y):\n",
    "    count_1 = np.count_nonzero(data_Y == 1)\n",
    "    count_0 = np.count_nonzero(data_Y == 0)\n",
    "    count_others = np.count_nonzero((data_Y != 1) & (data_Y != 0))\n",
    "    ratio_1 = round(count_1/len(data_Y)*100,2)\n",
    "    ratio_0 = round(count_0/len(data_Y)*100,2)\n",
    "    ratio_others = round(count_others/len(data_Y)*100,2)\n",
    "    print(f'Distribution: 1=>{count_1}({ratio_1}%),  0=>{count_0}({ratio_0}%),  others=>{count_others}({ratio_others}%)')\n",
    "\n",
    "    \n",
    "def upsampling_auto(X,X_original,Y,up_ratio):\n",
    "    check_label_distribution(Y)\n",
    "    zero_idx = np.where(Y == 0)[0]\n",
    "    one_idx = np.where(Y == 1)[0]\n",
    "    other_idx = np.where((Y != 1) & (Y != 0))[0]\n",
    "    if len(other_idx > 0):\n",
    "        return X,Y\n",
    "    repeated_data_X = np.tile(X[one_idx], (up_ratio, 1, 1))\n",
    "    repeated_data_X_original = np.tile(X_original[one_idx], (up_ratio, 1, 1))\n",
    "    repeated_data_Y = np.tile(Y[one_idx], (up_ratio))\n",
    "\n",
    "    X_upsampled = np.vstack((X[zero_idx], repeated_data_X))\n",
    "    X_original_upsampled = np.vstack((X_original[zero_idx], repeated_data_X_original))\n",
    "\n",
    "    Y_upsampled = np.concatenate((Y[zero_idx], repeated_data_Y)) \n",
    "    return X_upsampled,X_original_upsampled, Y_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632dde32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ad79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "    X: numpy\n",
    "    feature_name_list : List\n",
    "    select_feature_list : List   (必須是feature_name_list的子集)\n",
    "Output\n",
    "    select_feature_list data\n",
    "\"\"\"\n",
    "def select_features(X, feature_name_list, select_feature_list):\n",
    "    invalid_features = set(select_feature_list) - set(feature_name_list)\n",
    "    if invalid_features:\n",
    "        raise ValueError(f\"Invalid features in select_feature_list: {invalid_features}\")\n",
    "    selected_feature_indices = [feature_name_list.index(feature) for feature in select_feature_list]\n",
    "    X_selected = X[:, :, selected_feature_indices]\n",
    "\n",
    "    return X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "958621ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_data(task_name_list,data_date,data_type, select_feature_list = [], batch_size = 256,use_upsample = False):\n",
    "    batch_size = 256\n",
    "    data_path = \"data/sample/standard_data\"\n",
    "    \n",
    "    #Feature name\n",
    "    df_feature = pd.read_csv(\"data/sample/full_feature_name.csv\")\n",
    "    feature_name_list = df_feature.columns.to_list()\n",
    "\n",
    "   \n",
    "    #dataset\n",
    "    dataset_dict = {}\n",
    "    original_data_dict = {}\n",
    "    for task_name in task_name_list:\n",
    "        X_scalar = np.load(f\"{data_path}/{data_type}_scalar_X_{task_name}.npy\", allow_pickle=True)\n",
    "        X_original = np.load(f\"{data_path}/{data_type}_X_{task_name}.npy\", allow_pickle=True)\n",
    "        X_original_with_id = np.load(f\"{data_path}/{data_type}_X_with_id_{task_name}.npy\", allow_pickle=True)\n",
    "        \n",
    "        if len(select_feature_list)>0:\n",
    "            X_scalar = select_features(X_scalar,feature_name_list,select_feature_list)\n",
    "            X_original = select_features(X_original,feature_name_list,select_feature_list)\n",
    "            feature_name_list = select_feature_list\n",
    "    \n",
    "            assert X_scalar.shape[2] == len(select_feature_list)\n",
    "            assert X_original.shape[2] == len(select_feature_list)\n",
    "        X_original_with_id = X_original_with_id[:,:,:1]    \n",
    "        Y = np.load(f\"{data_path}/20240129_{data_type}_Y_{task_name}.npy\", allow_pickle=True)\n",
    "        \n",
    "        if use_upsample:\n",
    "            if task_name == 'Weaning_successful' and data_type == 'test':\n",
    "                X_scalar,X_original,Y = upsampling_auto(X_scalar,X_original,Y,2)\n",
    "        dataset_dict[task_name] = MyDataset(X_scalar,X_original,Y)\n",
    "        original_data_dict['X_scalar'] = X_scalar\n",
    "        original_data_dict['X'] = X_original\n",
    "        original_data_dict['X_with_id'] = X_original_with_id\n",
    "        original_data_dict['Y'] = Y\n",
    "    \n",
    "    #dataloader\n",
    "    loader_dict = {}\n",
    "    for key, dataset in dataset_dict.items():        \n",
    "        loader_dict[key] = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataset_dict,loader_dict,feature_name_list,original_data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70496de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTL_to_STL(multi_task_model):\n",
    "    single_task_models = {}\n",
    "\n",
    "    for task_index, task_name in enumerate(multi_task_model.task_name_list):\n",
    "        \n",
    "        single_task_model = MLP_MTL(input_dim, [task_name])  \n",
    "        single_task_model.to(device) \n",
    "\n",
    "        single_task_model.bt_fc1.weight.data = multi_task_model.bt_fc1.weight.data.clone()\n",
    "        single_task_model.bt_fc1.bias.data = multi_task_model.bt_fc1.bias.data.clone()\n",
    "\n",
    "        single_task_model.bt_fc2.weight.data = multi_task_model.bt_fc2.weight.data.clone()\n",
    "        single_task_model.bt_fc2.bias.data = multi_task_model.bt_fc2.bias.data.clone()\n",
    "\n",
    "        single_task_model.bt_fc3.weight.data = multi_task_model.bt_fc3.weight.data.clone()\n",
    "        single_task_model.bt_fc3.bias.data = multi_task_model.bt_fc3.bias.data.clone()\n",
    "\n",
    "        single_task_model.task_fc0[0].weight.data = multi_task_model.task_fc0[task_index].weight.data.clone()\n",
    "        single_task_model.task_fc0[0].bias.data = multi_task_model.task_fc0[task_index].bias.data.clone()\n",
    "\n",
    "        single_task_model.task_fc1[0].weight.data = multi_task_model.task_fc1[task_index].weight.data.clone()\n",
    "        single_task_model.task_fc1[0].bias.data = multi_task_model.task_fc1[task_index].bias.data.clone()\n",
    "\n",
    "        single_task_models[task_name] = single_task_model\n",
    "    return single_task_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be71fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_feature_important(shap_value,feature_name_list):\n",
    "    abs_shap_value = np.abs(shap_value)\n",
    "    sum_per_feature = np.sum(abs_shap_value, axis=0)\n",
    "    sorted_feature_indices = np.argsort(sum_per_feature)[::-1] #[::-1]是reversed\n",
    "    sorted_feature_names = [feature_name_list[i] for i in sorted_feature_indices]\n",
    "    return sorted_feature_names, sum_per_feature\n",
    "\n",
    "def get_model_shap(model,data_X_train,data_X_test,data_X_test_original,feature_name_list,task_name,use_mini_sample = True,n_sample = 100):\n",
    "    \n",
    "    max_sample = 1000\n",
    "    \n",
    "    seq_day = data_X_train.shape[1]\n",
    "    feature_count = data_X_train.shape[2]\n",
    "    \n",
    "    if use_mini_sample:\n",
    "        background_data = torch.from_numpy(data_X_train[:max_sample]).float().to(device)\n",
    "        shap_data = torch.from_numpy(data_X_test[:max_sample]).float().to(device)\n",
    "        shap_data_original = torch.from_numpy(data_X_test_original[:max_sample]).float().to(device)\n",
    "    else:\n",
    "        background_data = torch.from_numpy(data_X_train[:]).float().to(device)\n",
    "        shap_data = torch.from_numpy(data_X_test[:]).float().to(device)\n",
    "        shap_data_original = torch.from_numpy(data_X_test_original[:]).float().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    explainer = shap.GradientExplainer(model, background_data)\n",
    "    \n",
    "    shap_values = explainer.shap_values(shap_data,nsamples=n_sample)\n",
    "    shap_values = np.array(shap_values)\n",
    "    \n",
    "    shap_value_flatten = np.zeros((len(shap_data),seq_day*feature_count))\n",
    "    shap_data_flatten = np.zeros((len(shap_data),seq_day*feature_count))\n",
    "    \n",
    "    for i in range(0,len(shap_data)):\n",
    "        count=0\n",
    "        for j in range(feature_count):\n",
    "            for k in range(seq_day):\n",
    "                shap_value_flatten[i][count]=shap_values[i][k][j]  \n",
    "                shap_data_flatten[i][count]=shap_data_original[i][k][j]  \n",
    "                count += 1\n",
    "    feature_important,_ = calculate_feature_important(shap_value_flatten, feature_name_list)\n",
    "    return feature_important, shap_value_flatten, shap_data_flatten\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "    shap_value_flatten (sample,feature_flatten)\n",
    "    shap_data_flatten (sample,feature_flatten)\n",
    "    max_display \n",
    "\"\"\"\n",
    "def show_shap(shap_value_flatten, shap_data_flatten,feature_name_list, max_display = 20,task_name = ''):\n",
    "    fig = shap.summary_plot(shap_value_flatten,shap_data_flatten,feature_names=feature_name_list, show=False,max_display = max_display)\n",
    "    #plt.title(f\"***Task:{task_name}***\")\n",
    "    plt.xticks(fontsize=20, fontweight='bold', fontfamily='Arial')\n",
    "    plt.yticks(fontsize=20, fontweight='bold', fontfamily='Arial')\n",
    "    plt.xlabel('SHAP Value',fontsize=24, fontweight='bold', fontfamily='Arial')\n",
    "    \n",
    "    ax = plt.gca()  \n",
    "    #plt.savefig(f'./PDP/SHAP.tif', bbox_inches = 'tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5616fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdp_plot(x, y, feature_name, point_color='black'):\n",
    "    point_size = 4\n",
    "    #plt.figure(figsize=(6,4))\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    plt.scatter(x, y, color=point_color,s=point_size)\n",
    "    #plt.xlabel(feature_name)\n",
    "    plt.xlabel(feature_name, fontsize=26, fontweight='bold', fontfamily='Arial')\n",
    "    plt.ylabel('SHAP Value', fontsize=26, fontweight='bold', fontfamily='Arial')\n",
    "    plt.tick_params(axis='both', which='both', labelsize=18)\n",
    "    plt.legend()\n",
    "    \n",
    "    if feature_name == 'Peak Airway Pressure':\n",
    "        plt.xticks([10,13,16,19,22,25], [10,13,16,19,22,25])\n",
    "    if feature_name == 'RASS':\n",
    "        plt.xticks([-5,-4,-3,-2,-1,0,1,2,3], [-5,-4,-3,-2,-1,0,1,2,3])\n",
    "    if feature_name == 'FiO2':\n",
    "        plt.xticks([20,40,60,80,100], [20,40,60,80,100])\n",
    "    plt.xticks(fontweight='bold')\n",
    "    plt.yticks([])\n",
    "    plt.legend().set_visible(False)\n",
    "    #plt.legend(loc='lower center')\n",
    "    #plt.savefig(f'./PDP/{feature_name}.png', bbox_inches = 'tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a053c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "\"\"\" Calibration curve \"\"\"\n",
    "def plot_calibration_curve(model_list,model_name_list,x,y,task_name,num_bins=40):\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        \n",
    "    assert len(model_list) == len(model_name_list)\n",
    "    \n",
    "    for i in range(len(model_list)):\n",
    "        model = model_list[i]\n",
    "        model.eval()\n",
    "        if torch.is_tensor(x):\n",
    "            x = x.cpu().numpy()\n",
    "            #y = y.cpu().numpy()\n",
    "        x = torch.from_numpy(x).float().to(device)\n",
    "        y_true = y\n",
    "        out = model(x)\n",
    "        y_pred_prob = out[:,:]\n",
    "        y_pred_prob = y_pred_prob.float().cpu().detach().numpy()\n",
    "        \n",
    "        prob_true, prob_pred = calibration_curve(y_true, y_pred_prob, n_bins=num_bins, strategy='quantile')\n",
    "        perfect_model = np.linspace(0, 1, num_bins)\n",
    "        \n",
    "        hoose_colar = 'darkorange'\n",
    "        if i == 1:\n",
    "            choose_colar = 'blue'\n",
    "        else:\n",
    "            choose_colar = 'green'\n",
    "        choose_colar = 'black'\n",
    "        \n",
    "        #plt.plot(prob_pred, prob_true, color=choose_colar, label= f'{model_name_list[i]}')\n",
    "        #plt.plot(prob_pred, prob_true, marker='o', color='black', label= f'{model_name_list[i]}')\n",
    "        plt.plot(prob_pred, prob_true, marker='o', color='black')\n",
    "        \n",
    "    font_properties = {'size': 18,  'family': 'Arial', 'fontweight':'bold'}\n",
    "    plt.xticks(fontproperties='Arial', **font_properties)\n",
    "    plt.yticks(fontproperties='Arial', **font_properties)\n",
    "    \n",
    "    #plt.plot(perfect_model, perfect_model, color='black', linestyle='--', label='Perfectly calibrated')\n",
    "    plt.plot(perfect_model, perfect_model, color='black', linestyle='--')\n",
    "    plt.xlabel('Average Predicted Probability', fontsize=24, fontweight='bold', fontfamily='Arial') #平均預測機率\n",
    "    plt.ylabel('Ratio of Positives', fontsize=24, fontweight='bold', fontfamily='Arial')\n",
    "    #plt.title(f'Calibration Chart')\n",
    "    #plt.legend()\n",
    "    plt.legend().set_visible(False)\n",
    "    #plt.savefig(f'./FG2/calibration.png', bbox_inches = 'tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\" AUROC curve \"\"\"\n",
    "def plot_roc_curve(model_list,model_name_list,x,y,task_name):\n",
    "    #plt.figure(figsize=(5, 5))\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        \n",
    "    assert len(model_list) == len(model_name_list)\n",
    "    for i in range(len(model_list)):\n",
    "        model = model_list[i]\n",
    "        model.eval()\n",
    "        if torch.is_tensor(x):\n",
    "            x = x.cpu().numpy()\n",
    "            #y = y.cpu().numpy()\n",
    "        x = torch.from_numpy(x).float().to(device)\n",
    "        y_true = y\n",
    "        out = model(x)\n",
    "        y_pred_prob = out[:,:]\n",
    "        y_pred_prob = y_pred_prob.float().cpu().detach().numpy()\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        choose_colar = 'black'    \n",
    "        #plt.plot(fpr, tpr, marker='o', lw=2, label=f'{model_name_list[i]}({roc_auc:.4f})')\n",
    "        plt.plot(fpr, tpr, color=choose_colar, lw=2)\n",
    "        plt.plot([0, 1], [0, 1], color=choose_colar, lw=2, linestyle='--')\n",
    "        \n",
    "    plt.xlabel('False Positive Rate', fontsize=24, fontweight='bold', fontfamily='Arial')\n",
    "    plt.ylabel('True Positive Rate', fontsize=24, fontweight='bold', fontfamily='Arial')\n",
    "    font_properties = {'size': 18,  'family': 'Arial', 'fontweight':'bold'}\n",
    "    plt.xticks(fontproperties='Arial', **font_properties)\n",
    "    plt.yticks(fontproperties='Arial', **font_properties)\n",
    "    plt.legend().set_visible(False)\n",
    "    #plt.savefig(f'./FG2/AUROC.png', bbox_inches = 'tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\" AUPRC \"\"\"\n",
    "def plot_pr_curve(model_list,model_name_list, x, y, task_name):\n",
    "                  \n",
    "    for i in range(len(model_list)):\n",
    "        model = model_list[i]\n",
    "                  \n",
    "        if torch.is_tensor(x):\n",
    "            x = x.numpy()\n",
    "            y = y.numpy()\n",
    "        model.eval()\n",
    "        x = torch.from_numpy(x).float().to(device)\n",
    "        y_true = y\n",
    "        out = model(x)\n",
    "        y_pred_prob = out[:, :]\n",
    "        y_pred_prob = y_pred_prob.float().cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_pred_prob)\n",
    "        auprc = auc(recall, precision)\n",
    "\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot(recall, precision, color='darkorange', lw=2, label=f'{model_name_list[i]}({auprc:.2f})')\n",
    "        #plt.plot(recall, precision, color='darkorange', lw=2, label=f'Precision-Recall curve (area = {auprc:.2f})')\n",
    "    plt.xlabel('False Positive Rate', fontsize=24, fontweight='bold', fontfamily='Arial')\n",
    "    plt.ylabel('True Positive Rate', fontsize=24, fontweight='bold', fontfamily='Arial')\n",
    "    font_properties = {'size': 18,  'family': 'Arial', 'fontweight':'bold'}\n",
    "    plt.xticks(fontproperties='Arial', **font_properties)\n",
    "    plt.yticks(fontproperties='Arial', **font_properties)\n",
    "    plt.legend().set_visible(False)\n",
    "    #plt.savefig(f'./FG2/AUPRC.png', bbox_inches = 'tight', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def calculate_net_benefit_model(thresh_group, y_pred_score, y_label):\n",
    "    net_benefit_model = np.array([])\n",
    "    for thresh in thresh_group:\n",
    "        y_pred_label = y_pred_score > thresh\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, y_pred_label).ravel()\n",
    "        n = len(y_label)\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_model = np.append(net_benefit_model, net_benefit)\n",
    "    return net_benefit_model\n",
    "\n",
    "\n",
    "def calculate_net_benefit_all(thresh_group, y_label):\n",
    "    net_benefit_all = np.array([])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_label, y_label).ravel()\n",
    "    total = tp + tn\n",
    "    for thresh in thresh_group:\n",
    "        net_benefit = (tp / total) - (tn / total) * (thresh / (1 - thresh))\n",
    "        net_benefit_all = np.append(net_benefit_all, net_benefit)\n",
    "    return net_benefit_all\n",
    "\n",
    "\n",
    "def plot_DCA(ax, thresh_group, net_benefit_model, net_benefit_all , model_id,model_name_list):\n",
    "    \n",
    "    choose_colar = 'darkorange'\n",
    "    if model_id == 1:\n",
    "        choose_colar = 'blue'\n",
    "    elif model_id == 2:\n",
    "        choose_colar = 'green'\n",
    "    else:\n",
    "        choose_colar = 'red'\n",
    "    \n",
    "    choose_colar = 'black'\n",
    "    #Plot\n",
    "\n",
    "    ax.plot(thresh_group, net_benefit_model, color = choose_colar)\n",
    "    #ax.plot(thresh_group, net_benefit_model, color = choose_colar, label = f'{model_name_list[model_id]}')\n",
    "    \n",
    "    if model_id == 1:\n",
    "        #ax.plot(thresh_group, net_benefit_all, color = 'black',label = 'Treat all')\n",
    "        #ax.plot((0, 1), (0, 0), color = 'black', linestyle = ':', label = 'Treat none')\n",
    "        ax.plot(thresh_group, net_benefit_all, color = 'black')\n",
    "        ax.plot((0, 1), (0, 0), color = 'black', linestyle = ':')\n",
    "    ax.plot(thresh_group, net_benefit_all, color = 'black')\n",
    "    ax.plot((0, 1), (0, 0), color = 'black', linestyle = ':')\n",
    "    \n",
    "    #Fill，显示出模型较于treat all和treat none好的部分\n",
    "    y2 = np.maximum(net_benefit_all, 0)\n",
    "    y1 = np.maximum(net_benefit_model, y2)\n",
    "    ax.fill_between(thresh_group, y1, y2, color = 'black', alpha = 0.2)\n",
    "    \n",
    "    font_properties = {'size': 18,  'family': 'Arial', 'fontweight':'bold'}\n",
    "    plt.xticks(fontproperties='Arial', **font_properties)\n",
    "    plt.yticks(fontproperties='Arial', **font_properties)\n",
    "    \n",
    "    #Figure Configuration， 美化一下细节\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(net_benefit_model.min() - 0.15, net_benefit_model.max() + 0.15)#adjustify the y axis limitation\n",
    "    ax.set_xlabel(\n",
    "        xlabel = 'Threshold Probability', \n",
    "        fontdict= {'fontfamily':'Arial', 'fontsize': 24, 'fontweight':'bold'}\n",
    "        )\n",
    "    ax.set_ylabel(\n",
    "        ylabel = 'Net Benefit', \n",
    "        fontdict= {'fontfamily':'Arial', 'fontsize': 24, 'fontweight':'bold'}\n",
    "        )\n",
    "    \n",
    "    #ax.grid('major')\n",
    "    ax.spines['right'].set_color((0.8, 0.8, 0.8))\n",
    "    ax.spines['top'].set_color((0.8, 0.8, 0.8))\n",
    "    #ax.legend(loc = 'upper right')\n",
    "    plt.legend().set_visible(False)\n",
    "\n",
    "    return ax\n",
    "\n",
    "def decision_curve(model_list,model_name_list,x,y,task_name):\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        \n",
    "    assert len(model_list) == len(model_name_list)\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(len(model_list)):\n",
    "        model = model_list[i]\n",
    "        model.eval()\n",
    "        if torch.is_tensor(x):\n",
    "            x = x.cpu().numpy()\n",
    "            #y = y.cpu().numpy()\n",
    "        x = torch.from_numpy(x).float().to(device)\n",
    "        y_label = y\n",
    "        out = model(x)\n",
    "        y_pred_score = out[:,:]\n",
    "        y_pred_score = y_pred_score.float().cpu().detach().numpy()\n",
    "        y_pred = (y_pred_score > 0.5).astype(int)\n",
    "        \n",
    "        ########################################\n",
    "        thresh_group = np.arange(0,1,0.01)\n",
    "        net_benefit_model = calculate_net_benefit_model(thresh_group, y_pred_score, y_label)\n",
    "        net_benefit_all = calculate_net_benefit_all(thresh_group, y_label)\n",
    "        #fig, ax = plt.subplots()\n",
    "        #ax = plot_DCA(ax, thresh_group, net_benefit_model, net_benefit_all)\n",
    "        plot_DCA(ax, thresh_group, net_benefit_model, net_benefit_all,i,model_name_list)\n",
    "    # fig.savefig('fig1.png', dpi = 300)\n",
    "    #plt.savefig(f'./FG2/Decision.png', bbox_inches = 'tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff3ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "491b737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from datetime import datetime\n",
    "\n",
    "def group_result(df):\n",
    "    agg_columns = {\n",
    "        'acc': ['mean', 'std'],\n",
    "        'pre': ['mean', 'std'],\n",
    "        'f1': ['mean', 'std'],\n",
    "        'recall': ['mean', 'std'],\n",
    "        'auroc': ['mean', 'std'],\n",
    "        'brier_score': ['mean', 'std']\n",
    "    }\n",
    "    df_group = df.groupby('task').agg(agg_columns)\n",
    "    df_group.columns = [f\"{col[0]}_{col[1]}\" for col in df_group.columns]\n",
    "\n",
    "    for metric in ['acc', 'pre', 'f1', 'recall', 'auroc','brier_score']:\n",
    "        df_group[f\"{metric}_combined\"] = df_group.apply(\n",
    "            lambda row: f\"{row[f'{metric}_mean']:.4f} ± {row[f'{metric}_std']:.4f}\", axis=1\n",
    "        )\n",
    "\n",
    "    df_result = df_group[[f\"{metric}_combined\" for metric in ['acc', 'pre', 'f1', 'recall', 'auroc','brier_score']]]\n",
    "\n",
    "    df_result.reset_index(inplace=True)\n",
    "    df_result.columns = ['task','acc', 'pre', 'f1', 'recall', 'auroc','brier_score']\n",
    "    return df_result\n",
    "\n",
    "\n",
    "def save_to_xlsx(df_save,file_name = 'output'):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(df_save, index=False, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "    wb.save(f'{file_name}.xlsx')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31150f",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edb78051",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'Weaning_successful'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b237e1",
   "metadata": {},
   "source": [
    "# Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31211395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 18\n"
     ]
    }
   ],
   "source": [
    "path = \"./model/group_result/mtl_group/vent_group\"\n",
    "df_feature = pd.read_csv(f\"{path}/feature_name_list.csv\")\n",
    "select_feature_list = df_feature['Feature'].tolist()\n",
    "input_dim = len(select_feature_list)\n",
    "loss_func = BCEFocalLoss(alpha=alpha, gamma=gamma)\n",
    "\n",
    "\n",
    "train_dataset_dict,train_loader_dict,feature_name_list,_ = read_data([task_name],\"\",'train',select_feature_list,batch_size = batch_size,use_upsample = use_upsample)\n",
    "val_dataset_dict,val_loader_dict,_ ,_= read_data([task_name],\"\",'validation',select_feature_list,batch_size = batch_size,use_upsample = use_upsample)\n",
    "test_dataset_dict,test_loader_dict,_ ,original_data_dict= read_data([task_name],\"\",'test',select_feature_list,batch_size = batch_size,use_upsample = use_upsample)\n",
    "\n",
    "print(f'input_dim: {input_dim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdda402",
   "metadata": {},
   "source": [
    "# MTL_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08a3908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'lite'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f316f2e",
   "metadata": {},
   "source": [
    "# Vent_Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "590e92fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Weaning_successful': {'task': 'Weaning_successful', 'auroc': 0.821, 'acc': 0.758, 'f1': 0.598, 'pre': 0.66, 'recall': 0.546, 'brier_score': 0.165, 'loss': 6.205740544593265e-05}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Weaning_successful (Vent_group) \"\"\"\n",
    "\"\"\" best model \"\"\"\n",
    "data_path = \"./model/group_result/mtl_group/vent_group\"\n",
    "model_vent = MLP_MTL(input_dim, task_name_list).to(device)\n",
    "model_vent.load_state_dict(torch.load(f'{data_path}/{task_name}_best_{mode}'))\n",
    "result,_ = test(model_vent, test_dataset_dict, loss_func, is_show = False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d1aa8",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8031efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important, shap_value_flatten, shap_data_flatten = get_model_shap(\n",
    "                                                            model_vent,\n",
    "                                                            train_dataset_dict[task_name].inputs.numpy(),\n",
    "                                                            train_dataset_dict[task_name].inputs.numpy(),\n",
    "                                                            train_dataset_dict[task_name].inputs_original.numpy(),\n",
    "                                                            select_feature_list,\n",
    "                                                            task_name,\n",
    "                                                            use_mini_sample = False,\n",
    "                                                            n_sample = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f0d1d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'error_analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_feature_important \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      2\u001b[0m df_feature_important[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m feature_important\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdf_feature_important\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./error_analysis/feature_important.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'error_analysis'"
     ]
    }
   ],
   "source": [
    "df_feature_important = pd.DataFrame()\n",
    "df_feature_important['Feature'] = feature_important\n",
    "df_feature_important.to_csv('./error_analysis/feature_important.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db011112",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_feature_list = ['APACHE III' if item == 'apsiii' else item for item in select_feature_list]\n",
    "new_feature_list = ['Fluid balance' if item == 'total' else item for item in new_feature_list]\n",
    "new_feature_list = ['Urine output' if item == 'Urine_value' else item for item in new_feature_list]\n",
    "new_feature_list = ['Enteral feeding' if item == 'Nutrition_Enteral_value' else item for item in new_feature_list]\n",
    "new_feature_list = ['Fluid input' if item == 'Fluid_intake_value' else item for item in new_feature_list]\n",
    "\n",
    "show_shap(shap_value_flatten, shap_data_flatten,new_feature_list,task_name = task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def data_select(feature_name,shap_data,shap_value,indedx_of_feature):\n",
    "    if feature_name == 'Nutrition_Enteral_value':\n",
    "        select_indices1 = np.where(shap_value_flatten[:, indedx_of_feature] <= 0.7)[0]\n",
    "        select_indices2 = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) != 865)[0]\n",
    "        select_indices3 = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) <= 1500)[0]\n",
    "        select_indices4 = np.where(shap_value_flatten[:, indedx_of_feature] > -0.7)[0]\n",
    "        select_indices5 = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) != 1000)[0]\n",
    "        select_indices6 = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) != 999)[0]\n",
    "\n",
    "        select_indices = list(set(select_indices1) & set(select_indices2))\n",
    "        select_indices = list(set(select_indices) & set(select_indices3))\n",
    "        select_indices = list(set(select_indices) & set(select_indices4))\n",
    "        select_indices = list(set(select_indices) & set(select_indices5))\n",
    "        select_indices = list(set(select_indices) & set(select_indices6))\n",
    "\n",
    "        return shap_data[select_indices,indedx_of_feature], shap_value[select_indices,indedx_of_feature]\n",
    "    elif feature_name == 'apsiii':\n",
    "        select_indices1 = np.where(shap_value_flatten[:, indedx_of_feature] <= 0.4)[0]\n",
    "        select_indices2 = np.where(shap_value_flatten[:, indedx_of_feature] >= -0.4)[0]\n",
    "        select_indices = list(set(select_indices1) & set(select_indices2))\n",
    "        return shap_data[select_indices,indedx_of_feature], shap_value[select_indices,indedx_of_feature]\n",
    "        \n",
    "    elif feature_name == 'Peak Airway Pressure':\n",
    "        select_indices1 = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) <= 25)[0]\n",
    "        select_indices2 = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) >= 10)[0]\n",
    "        select_indices3 = np.where(shap_value_flatten[:, indedx_of_feature] <= 0.7)[0]\n",
    "        #select_indices4 = np.where(shap_value_flatten[:, indedx_of_feature] >= -0.5)[0]\n",
    "\n",
    "        select_indices = list(set(select_indices1) & set(select_indices2))\n",
    "        select_indices = list(set(select_indices) & set(select_indices3))\n",
    "        #select_indices = list(set(select_indices) & set(select_indices4))\n",
    "        return shap_data[select_indices,indedx_of_feature], shap_value[select_indices,indedx_of_feature]\n",
    "    elif feature_name == 'RASS':\n",
    "        select_indices1 = np.where(shap_value_flatten[:, indedx_of_feature] >= -0.4)[0]\n",
    "\n",
    "        select_indices = list(set(select_indices1) & set(select_indices1))\n",
    "        return shap_data[select_indices,indedx_of_feature], shap_value[select_indices,indedx_of_feature]\n",
    "    elif feature_name == 'Urine_value':\n",
    "        select_indices = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) <= 2500)[0]\n",
    "        return shap_data[select_indices,indedx_of_feature], shap_value[select_indices,indedx_of_feature]\n",
    "    elif feature_name == 'total':\n",
    "        select_indices1 = np.where(shap_value_flatten[:, indedx_of_feature] >= -0.2)[0]\n",
    "        select_indices2 = np.where(shap_value_flatten[:, indedx_of_feature] <= 0.25)[0]\n",
    "\n",
    "        select_indices = list(set(select_indices1) & set(select_indices2))\n",
    "        return shap_data[select_indices,indedx_of_feature], shap_value[select_indices,indedx_of_feature]\n",
    "   \n",
    "    elif feature_name == 'FiO2':\n",
    "\n",
    "        return shap_data[:,indedx_of_feature], shap_value[:,indedx_of_feature]\n",
    "\n",
    "    else:\n",
    "        select_indices = np.where(shap_data_flatten[:, indedx_of_feature].astype(int) !=  -99999)[0]\n",
    "        return shap_data[select_indices,indedx_of_feature], shap_value[select_indices,indedx_of_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d3869",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature_name in feature_important[:7]:\n",
    "    indedx_of_feature = feature_name_list.index(feature_name)\n",
    "    \n",
    "    shap_data,shap_value = data_select(feature_name,shap_data_flatten,shap_value_flatten,indedx_of_feature)\n",
    "\n",
    "    print(feature_name)\n",
    "\n",
    "    if feature_name == 'apsiii':\n",
    "        name = 'APACHE III'\n",
    "    elif feature_name == 'total':\n",
    "        name = 'Fluid balance'\n",
    "    elif feature_name == 'Nutrition_Enteral_value':\n",
    "        name = 'Enteral feeding'\n",
    "    else:\n",
    "        name = feature_name\n",
    "        \n",
    "    pdp_plot(\n",
    "        shap_data, \n",
    "        shap_value, \n",
    "        name\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_vent]\n",
    "model_name_list = ['MTL with Vent'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d862562",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(model_list,model_name_list,test_dataset_dict['Weaning_successful'].inputs.cpu(),test_dataset_dict['Weaning_successful'].labels.cpu(),'Weaning_successful')\n",
    "\n",
    "plot_roc_curve(model_list,model_name_list,test_dataset_dict['Weaning_successful'].inputs.cpu(),test_dataset_dict['Weaning_successful'].labels.cpu(),'Weaning_successful')\n",
    "\n",
    "decision_curve(model_list,model_name_list,train_dataset_dict['Weaning_successful'].inputs,train_dataset_dict['Weaning_successful'].labels,'Weaning_successful') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95439f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b191ad74",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922329e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_community.common.constants import ShapValuesOutput, ModelTask\n",
    "from interpret.ext.blackbox import MimicExplainer\n",
    "from interpret.ext.glassbox import LGBMExplainableModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Explainer Used: Mimic Explainer\n",
    "from interpret.ext.blackbox import MimicExplainer\n",
    "from interpret.ext.glassbox import LinearExplainableModel\n",
    "from interpret.ext.glassbox import LGBMExplainableModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from raiwidgets import ErrorAnalysisDashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(model, X):\n",
    "    task_name = model.task_name_list[0]\n",
    "    return model.predict(X)[task_name]\n",
    "\n",
    "def predict_proba_func(model, X):\n",
    "    task_name = model.task_name_list[0]\n",
    "    result = model.predict_proba(X)[task_name]\n",
    "    result = result.cpu().detach().numpy()\n",
    "    return result \n",
    "\n",
    "def create_model_pipeline(model):\n",
    "    model_pipeline = Pipeline([\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    model_pipeline.predict = lambda X: predict_func(model_pipeline.named_steps['model'], X)\n",
    "    model_pipeline.predict_proba = lambda X: predict_proba_func(model_pipeline.named_steps['model'], X)\n",
    "\n",
    "    return model_pipeline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = create_model_pipeline(model_vent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281719b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = train_dataset_dict['Weaning_successful'].inputs.numpy()\n",
    "X_train_original = np.squeeze(X_train_original)\n",
    "\n",
    "X_test_original_full = test_dataset_dict['Weaning_successful'].inputs.numpy()\n",
    "X_test_original_full = np.squeeze(X_test_original_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = X_test_original_full.shape[0]\n",
    "y_test_full = test_dataset_dict['Weaning_successful'].labels.numpy()\n",
    "X_test_original = X_test_original_full[:int(sample_count*0.9),:]\n",
    "y_test = y_test_full[:int(sample_count*0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_community.common.constants import ShapValuesOutput, ModelTask\n",
    "# 1. Using SHAP TabularExplainer\n",
    "model_task = ModelTask.Classification\n",
    "explainer = MimicExplainer(model_pipeline, X_train_original, LGBMExplainableModel,\n",
    "                           augment_data=True, max_num_of_augmentations=10,\n",
    "                           features=select_feature_list, classes=[0,1], model_task=model_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing in test dataset for evaluation examples - note it must be a representative sample of the original data\n",
    "# X_train can be passed as well, but with more examples explanations will take longer although they may be more accurate\n",
    "global_explanation = explainer.explain_global(X_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd487253",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_pipeline = create_model_pipeline(model_vent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1741f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ErrorAnalysisDashboard(global_explanation, dashboard_pipeline, dataset=X_test_original_full,\n",
    "                       true_y=y_test, categorical_features = [],\n",
    "                       true_y_dataset=y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc716d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scaler = joblib.load('./data/scaler_model.joblib')\n",
    "\n",
    "df_feature = pd.read_csv(f\"./data/sample/full_feature_name.csv\")\n",
    "\n",
    "feature_name_list = df_feature.columns.to_list()\n",
    "feature_count = len(feature_name_list)\n",
    "print(feature_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_feature(select_feature_list):\n",
    "    for i in range(len(select_feature_list)):\n",
    "        print(f'[{i+1}]...{select_feature_list[i]}')\n",
    "    \n",
    "    select_id = int(input('feature id = '))\n",
    "    value = float(input('value = '))\n",
    "    \n",
    "    return select_feature_list[select_id-1], value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38fcd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feature_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_name1, value1 = choose_feature(select_feature_list)\n",
    "feature_name1 = 'Mean Airway Pressure'\n",
    "value1 = 0.5\n",
    "\n",
    "index_of_feature1_full = feature_name_list.index(feature_name1)\n",
    "index_of_feature1_lite = select_feature_list.index(feature_name1)\n",
    "\n",
    "data = np.full(feature_count, value1)\n",
    "data = data.reshape(1,feature_count)\n",
    "\n",
    "original_value = scaler.inverse_transform(data)[0,index_of_feature1_full]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_name2, value2 = choose_feature(select_feature_list)\n",
    "feature_name2 = 'Nutrition_Enteral_value'\n",
    "value2 = 0.22\n",
    "\n",
    "index_of_feature2_full = feature_name_list.index(feature_name2)\n",
    "index_of_feature2_lite = select_feature_list.index(feature_name2)\n",
    "\n",
    "data = np.full(feature_count, value2)\n",
    "data = data.reshape(1,feature_count)\n",
    "\n",
    "original_value = scaler.inverse_transform(data)[0,index_of_feature2_full]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_name3, value3 = choose_feature(select_feature_list)\n",
    "feature_name3 = 'Nutrition_Enteral_value'\n",
    "value3 = 0.22\n",
    "\n",
    "index_of_feature3_full = feature_name_list.index(feature_name3)\n",
    "index_of_feature3_lite = select_feature_list.index(feature_name3)\n",
    "\n",
    "data = np.full(feature_count, value3)\n",
    "data = data.reshape(1,feature_count)\n",
    "\n",
    "original_value = scaler.inverse_transform(data)[0,index_of_feature3_full]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,data = read_data(task_name_list,'','test', select_feature_list =select_feature_list, batch_size = 256,use_upsample = False)\n",
    "\n",
    "X_scalar = data['X_scalar']\n",
    "X_original = data['X']\n",
    "Y = data['Y']\n",
    "\n",
    "dataset_dict = {}\n",
    "dataset_dict[task_name] = MyDataset(X_scalar,X_original,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_samples_np(data, feature_index, threshold, condition_type):\n",
    "    \"\"\"\n",
    "    Remove samples based on a specified condition on a specific feature.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy.ndarray): Input data with shape [sample, 1, feature].\n",
    "    - feature_index (int): Index of the feature.\n",
    "    - threshold (float): Threshold value for the condition.\n",
    "    - condition_type (str): Type of condition ('type1' for '<' or 'type2' for '>=').\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Updated data after removing samples.\n",
    "    \"\"\"\n",
    "    if condition_type == 'type1':\n",
    "        indices_to_remove = np.squeeze(np.argwhere(data[:, 0, feature_index] < threshold))\n",
    "    elif condition_type == 'type2':\n",
    "        indices_to_remove = np.squeeze(np.argwhere(data[:, 0, feature_index] <= threshold))\n",
    "    elif condition_type == 'type3':\n",
    "        indices_to_remove = np.squeeze(np.argwhere(data[:, 0, feature_index] > threshold))\n",
    "    elif condition_type == 'type4':\n",
    "        indices_to_remove = np.squeeze(np.argwhere(data[:, 0, feature_index] >= threshold))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid condition_type. Use 'type1' for '<' or 'type2' for '>='.\")\n",
    "    \n",
    "    return indices_to_remove\n",
    "\n",
    "    ## Remove samples\n",
    "    #data = np.delete(data, indices_to_remove, axis=0)\n",
    "    #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b62f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type1: <\n",
    "#type2: <=\n",
    "#type3: >\n",
    "#type4: >=\n",
    "\n",
    "indices_to_remove1 = remove_samples_np(X_scalar,index_of_feature1_lite,value1,'type2')\n",
    "indices_to_remove2 = remove_samples_np(X_scalar,index_of_feature2_lite,value2,'type3')\n",
    "indices_to_remove3 = remove_samples_np(X_scalar,index_of_feature3_lite,value3,'type3')\n",
    "\n",
    "common_indices = np.intersect1d(np.intersect1d(indices_to_remove1, indices_to_remove2), indices_to_remove3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781dcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(X_scalar.shape[0])\n",
    "not_selected_indices = np.setdiff1d(all_indices, common_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['X_with_id'][common_indices].shape)\n",
    "print(data['X_with_id'][not_selected_indices].shape)\n",
    "\n",
    "reserve_patient = data['X_with_id'][not_selected_indices,0,0].tolist()\n",
    "remove_patient = data['X_with_id'][common_indices,0,0].tolist()\n",
    "\n",
    "print(f'reserve: {len(reserve_patient)}')\n",
    "print(f'remove: {len(remove_patient)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b36ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_successful_patient = pd.DataFrame({'stay_id': reserve_patient, 'outcome': 'reserve'})\n",
    "df_fail_patient = pd.DataFrame({'stay_id': remove_patient, 'outcome': 'remove'})\n",
    "df_combined = pd.concat([df_successful_patient, df_fail_patient], ignore_index=True)\n",
    "\n",
    "np.save(\"./error_analysis/remove_patient.npy\", data['X'][common_indices])\n",
    "np.save(\"./error_analysis/reserve_patient.npy\", data['X'][not_selected_indices])\n",
    "df_combined.to_csv(\"./error_analysis/error患者.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20526c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'found: {len(common_indices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f75e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" remove sample \"\"\"\n",
    "X_scalar_remove = X_scalar[common_indices].copy()\n",
    "X_original_remove = X_original[common_indices].copy()\n",
    "Y_remove = Y[common_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e30513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" reserve sample \"\"\"\n",
    "full_indices = np.arange(0, Y.shape[0])\n",
    "keep_indices = np.array([i for i in full_indices if i not in common_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scalar_keep = X_scalar[keep_indices].copy()\n",
    "X_original_keep = X_original[keep_indices].copy()\n",
    "Y_keep = Y[keep_indices].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382de2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict_keep = {}\n",
    "dataset_dict_keep[task_name] = MyDataset(X_scalar_keep,X_original_keep,Y_keep)\n",
    "result_before_remove,_ = test(model_vent, test_dataset_dict, loss_func, is_show = False)\n",
    "result_after_remove,_ = test(model_vent, dataset_dict_keep, loss_func, is_show = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca96dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([result_before_remove['Weaning_successful'], result_after_remove['Weaning_successful']], index=['before', 'after'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ecad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = Y.copy()\n",
    "\n",
    "total_sample = Y.shape[0]\n",
    "count_zero = np.count_nonzero(arr == 0)\n",
    "count_one = np.count_nonzero(arr == 1)\n",
    "\n",
    "print(f'Total sample: {total_sample}')\n",
    "print(f\"Number of 0: {count_zero} ({round(count_zero/total_sample*100,2)}%)\")\n",
    "print(f\"Number of 1: {count_one} ({round(count_one/total_sample*100,2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr = Y_remove.copy()\n",
    "total_remove_sample = Y_remove.shape[0]\n",
    "count_zero = np.count_nonzero(arr == 0)\n",
    "count_one = np.count_nonzero(arr == 1)\n",
    "\n",
    "# 顯示結果\n",
    "print(f'remove sample: {total_remove_sample}')\n",
    "print(f\"Number of 0: {count_zero} ({round(count_zero/total_remove_sample*100,2)}%)\")\n",
    "print(f\"Number of 1: {count_one} ({round(count_one/total_remove_sample*100,2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, file_name, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "  \n",
    "    cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    \n",
    "    new_order = ['Class 1','Class 0']\n",
    "    new_order_columns = ['Class 1','Class 0']\n",
    "    cm_df = cm_df.reindex(new_order)\n",
    "    cm_df = cm_df.reindex(columns=new_order_columns)\n",
    "    \n",
    "    y_labels = list(reversed(classes))\n",
    "    x_labels = list(reversed(classes))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    font_properties = {'size': 20,  'family': 'Arial'}\n",
    "    title_font_properties = {'size': 20, 'weight': 'bold', 'family': 'Arial'}\n",
    "    \n",
    "    annot_kws = {'size': 20, 'weight': 'bold', 'family': 'Arial'}\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=cmap, cbar=False,\n",
    "                xticklabels=x_labels, yticklabels=y_labels, annot_kws=annot_kws)\n",
    "    \n",
    "    plt.xticks(fontproperties='Arial', **font_properties)\n",
    "    plt.yticks(fontproperties='Arial', **font_properties)\n",
    "    \n",
    "\n",
    "    plt.xlabel(title, fontproperties='Arial', **title_font_properties)\n",
    "    plt.ylabel(title, fontproperties='Arial', **title_font_properties)\n",
    "    \n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(f'./error_analysis/confusion_{file_name}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53272b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [1]full sample \"\"\"\n",
    "correct_count_0 = 0\n",
    "correct_count_1 = 0\n",
    "count_zero = np.count_nonzero(Y == 0)\n",
    "count_one = np.count_nonzero(Y == 1)\n",
    "count = 0\n",
    "pred_y = model_vent.predict(X_scalar)['Weaning_successful']\n",
    "\n",
    "for i in range(pred_y.shape[0]):\n",
    "    if Y[i] != pred_y[i]:\n",
    "        count+=1\n",
    "    if Y[i] == 1 and pred_y[i] == 1:\n",
    "        correct_count_1 += 1\n",
    "    if Y[i] == 0 and pred_y[i] == 0:\n",
    "        correct_count_0 += 1\n",
    "\n",
    "plot_confusion_matrix(Y,pred_y,['Class 0','Class 1'],'full')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c5caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [2]remove sample \"\"\"\n",
    "count_zero = np.count_nonzero(Y_remove == 0)\n",
    "count_one = np.count_nonzero(Y_remove == 1)\n",
    "correct_count_0 = 0\n",
    "correct_count_1 = 0\n",
    "\n",
    "pred_y = model_vent.predict(X_scalar_remove)['Weaning_successful']\n",
    "\n",
    "for i in range(pred_y.shape[0]):\n",
    "    if Y_remove[i] == 1 and pred_y[i] == 1:\n",
    "        correct_count_1 += 1\n",
    "    if Y_remove[i] == 0 and pred_y[i] == 0:\n",
    "        correct_count_0 += 1\n",
    "\n",
    "plot_confusion_matrix(Y_remove,pred_y,['Class 0','Class 1'],'remove_sample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [3]reserve sample \"\"\"\n",
    "count_zero = np.count_nonzero(Y_keep == 0)\n",
    "count_one = np.count_nonzero(Y_keep == 1)\n",
    "correct_count_0 = 0\n",
    "correct_count_1 = 0\n",
    "\n",
    "pred_y = model_vent.predict(X_scalar_keep)['Weaning_successful']\n",
    "\n",
    "for i in range(pred_y.shape[0]):\n",
    "    if Y_keep[i] == 1 and pred_y[i] == 1:\n",
    "        correct_count_1 += 1\n",
    "    if Y_keep[i] == 0 and pred_y[i] == 0:\n",
    "        correct_count_0 += 1\n",
    "\n",
    "plot_confusion_matrix(Y_keep,pred_y,['Class 0','Class 1'],'keep_sample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73b387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
