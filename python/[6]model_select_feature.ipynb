{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "984b565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import pickle\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, brier_score_loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edafeb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "gamma = 1\n",
    "seq_len = 1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 100\n",
    "experiment_time = 1\n",
    "\n",
    "#batch_size = 3200\n",
    "#max_epoch = 2\n",
    "#experiment_time = 5\n",
    "\n",
    "limit_early_stop_count = 5\n",
    "\n",
    "\n",
    "select_feature_flag = True\n",
    "calculate_shap = True\n",
    "\n",
    "\n",
    "use_upsample = False\n",
    "use_mini_feature = False\n",
    "\n",
    "if select_feature_flag:\n",
    "    calculate_shap = True\n",
    "    use_mini_feature = False\n",
    "    \n",
    "only_Weaning = False\n",
    "\n",
    "task_name_list = ['Weaning_successful','SBT_start','SBT_successful']\n",
    "#task_name_list = ['Weaning_successful','Mortality_30d','Vasopressor']\n",
    "#task_name_list = ['Weaning_successful']\n",
    "\n",
    "#data_date = \"20231216\"\n",
    "#data_date = \"20231224\"\n",
    "#data_date = \"20231226\"\n",
    "#data_date = \"20231227\"\n",
    "#data_date = \"20240104\"\n",
    "data_date = \"20240114\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "121e9861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "786bc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_MTL(nn.Module):\n",
    "    def __init__(self, input_dim, task_name_list, dropout_ratio=0.0):\n",
    "        super(MLP_MTL, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        self.relu = nn.ReLU()  # Activation function for hidden layers\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.task_name_list = task_name_list\n",
    "        self.num_tasks = len(task_name_list)\n",
    "        hidden_dim = [256, 128, 64, 32]\n",
    "        output_size = 1\n",
    "\n",
    "        # Bottom\n",
    "        self.bt_fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
    "        self.bt_fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "        self.bt_fc3 = nn.Linear(hidden_dim[1], hidden_dim[2])\n",
    "\n",
    "        # Towers\n",
    "        self.task_fc0 = nn.ModuleList([nn.Linear(hidden_dim[2], hidden_dim[3]) for _ in range(self.num_tasks)])\n",
    "        self.task_fc1 = nn.ModuleList([nn.Linear(hidden_dim[3], output_size) for _ in range(self.num_tasks)])\n",
    "    \n",
    "    def data_check(self,x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        if x.ndim == 3:\n",
    "            x = x.reshape(x.shape[0], x.shape[1] * x.shape[2])  # Flatten \n",
    "            \n",
    "        x = x.to(device)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.data_check(x)\n",
    "\n",
    "        # Bottom\n",
    "        x = self.bt_fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bt_fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bt_fc3(x)\n",
    "        h = self.relu(x)\n",
    "        h = self.dropout(h)  \n",
    "\n",
    "        # Towers\n",
    "        task_out = {}\n",
    "        for task_index in range(self.num_tasks):\n",
    "            task_name = self.task_name_list[task_index]\n",
    "            hi = self.task_fc0[task_index](h)\n",
    "            hi = self.relu(hi)\n",
    "            hi = self.dropout(hi)\n",
    "            hi = self.task_fc1[task_index](hi)\n",
    "            hi = self.sigmoid(hi)\n",
    "            task_out[task_name] = hi    \n",
    "            \n",
    "        if len(self.task_name_list) == 1:\n",
    "            return task_out[self.task_name_list[0]]\n",
    "        else:\n",
    "            return task_out\n",
    "    \n",
    "    def predict_prob(self, x):\n",
    "        self.eval()\n",
    "        prob_dict = self.forward(x)\n",
    "        \n",
    "        if len(self.task_name_list) == 1:\n",
    "            prob_dict_true = {}\n",
    "            prob_dict_true[self.task_name_list[0]] = prob_dict\n",
    "            return prob_dict_true\n",
    "        return prob_dict\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        self.eval()\n",
    "        prob_dict = self.forward(x)\n",
    "        \n",
    "        if len(self.task_name_list) == 1:\n",
    "            prob_dict_true = {}\n",
    "            prob_dict_true[self.task_name_list[0]] = prob_dict\n",
    "            return prob_dict_true\n",
    "        \n",
    "        return prob_dict\n",
    "    \n",
    "    def predict(self, x, threshold = 0.5):\n",
    "        self.eval()\n",
    "        prob_dict = self.predict_prob(x)\n",
    "        pred_dict = {}\n",
    "        \n",
    "        for key, value in prob_dict.items():\n",
    "            #tensor轉numpy\n",
    "            value = value.cpu().detach().numpy()\n",
    "            pred_class = [1 if x > threshold else 0 for x in value]\n",
    "            pred_dict[key] = np.array(pred_class) \n",
    "        return pred_dict\n",
    "    \n",
    "    def evaluate(self,X,label,task_name,criterion):\n",
    "        with torch.no_grad():\n",
    "            prob = self.predict_prob(X)[task_name].cpu().detach().numpy() #tensor=>numpy\n",
    "            pred = self.predict(X)[task_name] \n",
    "            score = compute_scores(label,pred,prob)\n",
    "            score['task'] = task_name\n",
    "            loss = criterion(torch.from_numpy(prob).to(device),torch.from_numpy(label).to(device)).item()\n",
    "            score['loss'] = loss/len(label)\n",
    "            return score\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8537c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(y_true, y_pred,y_prob):\n",
    "    if np.any(np.isnan(y_prob)):\n",
    "        print(y_prob)\n",
    "        input()\n",
    "        \n",
    "    scores = {}\n",
    "    try:\n",
    "        scores['task'] = 'Null'\n",
    "        scores['auroc'] = round(roc_auc_score(y_true, y_prob), 3)\n",
    "        scores['acc'] = round(accuracy_score(y_true, y_pred), 3)\n",
    "        scores['f1'] = round(f1_score(y_true, y_pred), 3)\n",
    "        scores['pre'] = round(precision_score(y_true, y_pred), 3)\n",
    "        scores['recall'] = round(recall_score(y_true, y_pred), 3)\n",
    "        scores['brier_score'] = round(brier_score_loss(y_true, y_prob), 3)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06f86098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader_dict, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    task_name_list = list(loader_dict.keys())\n",
    "\n",
    "    \"\"\"\n",
    "    cycle_loader\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    cycle_loader_dict = {}\n",
    "    for task_name, dataloader in loader_dict.items():\n",
    "        current_length = len(dataloader)\n",
    "        max_length = max(max_length, current_length)\n",
    "        cycle_loader_dict[task_name] = itertools.cycle(dataloader)\n",
    "\n",
    "    for i in range(max_length):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss = torch.zeros(1).to(device)\n",
    "        for task_name in task_name_list:  \n",
    "            data = next(cycle_loader_dict[task_name])\n",
    "            x = data[0].to(device)\n",
    "            label = data[1].unsqueeze(1).to(device)\n",
    "            prob = model.predict_prob(x)[task_name]\n",
    "            loss = criterion(prob, label)\n",
    "            total_loss += loss\n",
    "            if task_name == 'Weaning_successful':\n",
    "                total_loss += loss\n",
    "            \n",
    "        total_loss.backward()\n",
    "        train_loss+=total_loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for task_name in task_name_list: \n",
    "            if (i + 1) % len(loader_dict[task_name]) == 0:\n",
    "                cycle_loader_dict[task_name] = itertools.cycle(loader_dict[task_name])\n",
    "                \n",
    "    train_loss /= max_length* 256 * len(task_name_list)\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8daed213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    model\n",
    "    dict: Mydataset\n",
    "    loss_function\n",
    "Output:\n",
    "    score: dict + dict\n",
    "    result: dict => ['total_auc','total_loss']\n",
    "\"\"\"\n",
    "def test(model, dataset_dict, criterion, is_show = True , only_Weaning = False):\n",
    "    model.eval()\n",
    "\n",
    "    task_name_list = list(dataset_dict.keys())\n",
    "    score = {}\n",
    "    result = {'total_auc': 0, 'total_loss': 0}\n",
    "    for task_name in task_name_list:  # 循環每個任務\n",
    "        X = dataset_dict[task_name].inputs.numpy()\n",
    "        Y = dataset_dict[task_name].labels.unsqueeze(1).numpy()\n",
    "    \n",
    "        score[task_name] = model.evaluate(X,Y,task_name,criterion)\n",
    "        \n",
    "        if only_Weaning == True and 'Weaning_succecssful' in task_name_list:\n",
    "            if task_name == 'Weaning_succecssful':\n",
    "                result['total_auc'] = result['total_auc'] + score[task_name]['auroc']\n",
    "                result['total_loss'] = result['total_loss'] + score[task_name]['loss']\n",
    "        else:\n",
    "            result['total_auc'] = result['total_auc'] + score[task_name]['auroc']\n",
    "            result['total_loss'] = result['total_loss'] + score[task_name]['loss']\n",
    "            \n",
    "        if is_show:\n",
    "            print(score[task_name])\n",
    "    \n",
    "    return score,result\n",
    "\n",
    "\"\"\"\n",
    "local_best_model_dict: #dict{'task_name':{'model','performance(target_score)','id'}}\n",
    "model\n",
    "\"\"\"\n",
    "def test2(local_best_model_dict, modelr, dataset_dict, criterion, is_show = True):\n",
    "    score = {}\n",
    "    result = {'total_auc': 0, 'total_loss': 0}\n",
    "    task_name_list = list(dataset_dict.keys())\n",
    "    \n",
    "    for task_name in task_name_list:\n",
    "        print(f\"task: {task_name} \")\n",
    "        print(f\"{local_best_model_dict[task_name]['performance']}\")\n",
    "        modelr.load_state_dict(local_best_model_dict[task_name]['model'])\n",
    "        modelr.eval()\n",
    "        X = dataset_dict[task_name].inputs.numpy()\n",
    "        Y = dataset_dict[task_name].labels.unsqueeze(1).numpy()\n",
    "        score[task_name] = modelr.evaluate(X,Y,task_name,criterion)\n",
    "        result['total_auc'] = result['total_auc'] + score[task_name]['auroc']\n",
    "        result['total_loss'] = result['total_loss'] + score[task_name]['loss']\n",
    "        if is_show:\n",
    "            print(score[task_name])\n",
    "            \n",
    "    return score,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d074fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, np_X_scalar,np_X_original, np_Y):\n",
    "        self.inputs = torch.from_numpy(np_X_scalar).float()\n",
    "        self.inputs_original = torch.from_numpy(np_X_original).float()\n",
    "        self.labels = torch.from_numpy(np_Y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "    \n",
    "    def remove_samples(self, feature_index, threshold, condition_type):\n",
    "        \"\"\"\n",
    "        Remove samples based on a specified condition on a specific feature.\n",
    "\n",
    "        Parameters:\n",
    "        - feature_index (int): Index of the feature.\n",
    "        - threshold (float): Threshold value for the condition.\n",
    "        - condition_type (str): Type of condition ('type1' for '<' or 'type2' for '>=').\n",
    "        \"\"\"\n",
    "        if condition_type == 'type1':\n",
    "            indices_to_remove = torch.nonzero(self.inputs[:, feature_index] < threshold).squeeze()\n",
    "        elif condition_type == 'type2':\n",
    "            indices_to_remove = torch.nonzero(self.inputs[:, feature_index] >= threshold).squeeze()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid condition_type. Use 'type1' for '<' or 'type2' for '>='.\")\n",
    "\n",
    "        # Remove samples\n",
    "        self.inputs = torch.index_select(self.inputs, 0, indices_to_remove)\n",
    "        self.inputs_original = torch.index_select(self.inputs_original, 0, indices_to_remove)\n",
    "        self.labels = torch.index_select(self.labels, 0, indices_to_remove)\n",
    "    \n",
    "class BCEFocalLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=2, alpha=0.25, reduction='elementwise_mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    " \n",
    "    def forward(self, _input, target):\n",
    "        pt = _input\n",
    "        alpha = self.alpha\n",
    "        loss = - alpha * (1 - pt) ** self.gamma * target * torch.log(pt) - \\\n",
    "               (1 - alpha) * pt ** self.gamma * (1 - target) * torch.log(1 - pt)\n",
    "        if self.reduction == 'elementwise_mean':\n",
    "            loss = torch.mean(loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = torch.sum(loss)\n",
    "        return loss    \n",
    "\n",
    "    \n",
    "def check_label_distribution (data_Y):\n",
    "    count_1 = np.count_nonzero(data_Y == 1)\n",
    "    count_0 = np.count_nonzero(data_Y == 0)\n",
    "    count_others = np.count_nonzero((data_Y != 1) & (data_Y != 0))\n",
    "    ratio_1 = round(count_1/len(data_Y)*100,2)\n",
    "    ratio_0 = round(count_0/len(data_Y)*100,2)\n",
    "    ratio_others = round(count_others/len(data_Y)*100,2)\n",
    "    print(f'Distribution: 1=>{count_1}({ratio_1}%),  0=>{count_0}({ratio_0}%),  others=>{count_others}({ratio_others}%)')\n",
    "\n",
    "    \n",
    "def upsampling_auto(X,X_original,Y,up_ratio):\n",
    "    check_label_distribution(Y)\n",
    "    zero_idx = np.where(Y == 0)[0]\n",
    "    one_idx = np.where(Y == 1)[0]\n",
    "    other_idx = np.where((Y != 1) & (Y != 0))[0]\n",
    "    if len(other_idx > 0):\n",
    "        return X,Y\n",
    "    repeated_data_X = np.tile(X[one_idx], (up_ratio, 1, 1))\n",
    "    repeated_data_X_original = np.tile(X_original[one_idx], (up_ratio, 1, 1))\n",
    "    repeated_data_Y = np.tile(Y[one_idx], (up_ratio))\n",
    "\n",
    "    X_upsampled = np.vstack((X[zero_idx], repeated_data_X))\n",
    "    X_original_upsampled = np.vstack((X_original[zero_idx], repeated_data_X_original))\n",
    "\n",
    "    Y_upsampled = np.concatenate((Y[zero_idx], repeated_data_Y)) \n",
    "    return X_upsampled,X_original_upsampled, Y_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2ad79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "    X: numpy\n",
    "    feature_name_list : List\n",
    "    select_feature_list : List   (必須是feature_name_list的子集)\n",
    "Output\n",
    "    select_feature_list data\n",
    "\"\"\"\n",
    "def select_features(X, feature_name_list, select_feature_list):\n",
    "    invalid_features = set(select_feature_list) - set(feature_name_list)\n",
    "    if invalid_features:\n",
    "        raise ValueError(f\"Invalid features in select_feature_list: {invalid_features}\")\n",
    "    selected_feature_indices = [feature_name_list.index(feature) for feature in select_feature_list]\n",
    "    X_selected = X[:, :, selected_feature_indices]\n",
    "\n",
    "    return X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "958621ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    dataset_dict: Mydataset \n",
    "    loader_dict: Dataloader\n",
    "    feature_name_list: List\n",
    "    select_feature_list: List \n",
    "    batch_size: 256\n",
    "\n",
    "Output:\n",
    "    dataset_dict\n",
    "    loader_dict\n",
    "    feature_name_list ==>\n",
    "\"\"\"\n",
    "\n",
    "def read_data(task_name_list, data_date ,data_type, select_feature_list = [], batch_size = 256,use_upsample = False):\n",
    "    data_path = \"data/sample/standard_data\"\n",
    "    \n",
    "    #Feature name\n",
    "    df_feature = pd.read_csv(\"data/sample/full_feature_name.csv\")\n",
    "    feature_name_list = df_feature.columns.to_list()\n",
    "    \n",
    "    #Dataset\n",
    "    dataset_dict = {}\n",
    "    for task_name in task_name_list:\n",
    "        X_scalar = np.load(f\"{data_path}/{data_type}_scalar_X_{task_name}.npy\", allow_pickle=True)\n",
    "        X_original = np.load(f\"{data_path}/{data_type}_X_{task_name}.npy\", allow_pickle=True)\n",
    "        \n",
    "        if len(select_feature_list)>0:\n",
    "            X_scalar = select_features(X_scalar,feature_name_list,select_feature_list)\n",
    "            X_original = select_features(X_original,feature_name_list,select_feature_list)\n",
    "            assert X_scalar.shape[2] == len(select_feature_list)\n",
    "            assert X_original.shape[2] == len(select_feature_list)\n",
    "            \n",
    "        Y = np.load(f\"{data_path}\\\\{data_type}_Y_{task_name}.npy\", allow_pickle=True)\n",
    "        \n",
    "        if use_upsample:\n",
    "            if task_name == 'Weaning_successful' and data_type != 'test':\n",
    "                X_scalar,X_original,Y = upsampling_auto(X_scalar,X_original,Y,2)\n",
    "        dataset_dict[task_name] = MyDataset(X_scalar,X_original,Y)\n",
    "    \n",
    "    #Dataloader\n",
    "    loader_dict = {}\n",
    "    for key, dataset in dataset_dict.items():        \n",
    "        loader_dict[key] = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataset_dict,loader_dict,feature_name_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70496de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTL_to_STL(multi_task_model):\n",
    "    single_task_models = {}\n",
    "\n",
    "    for task_index, task_name in enumerate(multi_task_model.task_name_list):\n",
    "        \n",
    "        single_task_model = MLP_MTL(input_dim, [task_name])  \n",
    "        single_task_model.to(device) \n",
    "\n",
    "        single_task_model.bt_fc1.weight.data = multi_task_model.bt_fc1.weight.data.clone()\n",
    "        single_task_model.bt_fc1.bias.data = multi_task_model.bt_fc1.bias.data.clone()\n",
    "\n",
    "        single_task_model.bt_fc2.weight.data = multi_task_model.bt_fc2.weight.data.clone()\n",
    "        single_task_model.bt_fc2.bias.data = multi_task_model.bt_fc2.bias.data.clone()\n",
    "\n",
    "        single_task_model.bt_fc3.weight.data = multi_task_model.bt_fc3.weight.data.clone()\n",
    "        single_task_model.bt_fc3.bias.data = multi_task_model.bt_fc3.bias.data.clone()\n",
    "\n",
    "        single_task_model.task_fc0[0].weight.data = multi_task_model.task_fc0[task_index].weight.data.clone()\n",
    "        single_task_model.task_fc0[0].bias.data = multi_task_model.task_fc0[task_index].bias.data.clone()\n",
    "\n",
    "        single_task_model.task_fc1[0].weight.data = multi_task_model.task_fc1[task_index].weight.data.clone()\n",
    "        single_task_model.task_fc1[0].bias.data = multi_task_model.task_fc1[task_index].bias.data.clone()\n",
    "\n",
    "        single_task_models[task_name] = single_task_model\n",
    "    return single_task_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21cdcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(task_name_list, model_parm_dict, mode, time_id):\n",
    "\n",
    "    path = ''\n",
    "    if len(task_name_list) == 1:\n",
    "        path = \"./model/group_result/stl_group\"\n",
    "    elif 'SBT_start' in task_name_list:\n",
    "        path = \"./model/group_result/mtl_group/vent_group\"\n",
    "    else:\n",
    "        path = \"./model/group_result/mtl_group/mortality_group\"\n",
    "    \n",
    "    for task_name in task_name_list:\n",
    "        model_parm = model_parm_dict[task_name].state_dict().copy()\n",
    "\n",
    "        if mode == 'lite':\n",
    "            torch.save(model_parm, f'{path}/{task_name}_{time_id}_lite')\n",
    "        else:\n",
    "            torch.save(model_parm, f'{path}/{task_name}_{time_id}')\n",
    "\n",
    "def save_feature_name(feature_name_list,path,file_name):\n",
    "    df_feature = pd.DataFrame()\n",
    "    df_feature['Feature'] = feature_name_list\n",
    "    df_feature.to_csv(f'{path}/{file_name}.csv',index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a371a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    experiment_time\n",
    "    max_epoch\n",
    "    learning_rate\n",
    "    input_dim\n",
    "    task_name_list\n",
    "    train_loader_dict\n",
    "    val_dataset_dict\n",
    "    test_dataset_dict\n",
    "    device\n",
    "    is_show\n",
    "\n",
    "Output:\n",
    "    df_grade\n",
    "    stl_model_dict\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_and_test_model(experiment_time, max_epoch, learning_rate, input_dim, task_name_list, train_loader_dict, val_dataset_dict, test_dataset_dict, device,is_show = True , load_parm = {}):\n",
    "    df_grade = pd.DataFrame(columns=['time', 'task', 'auroc', 'acc', 'f1', 'pre', 'recall', 'brier_score', 'loss'])\n",
    "    best_model_params = {}\n",
    "    global_best_AUC = 0\n",
    "    global_best_loss = 10000\n",
    "    best_model_dict = {} \n",
    "    \n",
    "    count = 1\n",
    "    local_indicator = 'auroc'\n",
    "    global_indicator = 'loss'\n",
    "    \n",
    "    if len(load_parm)!=0:\n",
    "        assert len(task_name_list) == 1 or 'Weaning_successful' not in task_name_list, f'The number of tasks is not 1 => {task_name_list}'\n",
    "        \n",
    "        load_model = MLP_MTL(input_dim, task_name_list).to(device)\n",
    "        load_model.load_state_dict(load_parm)\n",
    "        load_model.eval()\n",
    "        \n",
    "        loss_func = BCEFocalLoss(alpha=alpha, gamma=gamma)\n",
    "        \n",
    "        result = test(load_model, test_dataset_dict, loss_func, is_show = True)\n",
    "        return load_model,result\n",
    "    \n",
    "    for time in range(experiment_time):\n",
    "        train_loss_list = []\n",
    "        val_loss_list = []\n",
    "        auc_list = []    \n",
    "        local_best_AUC = 0\n",
    "        local_best_loss = 10000\n",
    "        local_best_model_dict = {} \n",
    "        patience_counter = 0\n",
    "        \n",
    "        model = MLP_MTL(input_dim, task_name_list).to(device)\n",
    "        optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "        loss_func = BCEFocalLoss(alpha=alpha, gamma=gamma)\n",
    "        \n",
    "        for epoch in tqdm(range(max_epoch)):\n",
    "            if is_show:\n",
    "                print(f'Time:{time+1}/{experiment_time} - Epoch:{epoch+1}/{max_epoch}...')\n",
    "                \n",
    "            train_loss = train(model, train_loader_dict, loss_func, optimizer)\n",
    "            val_score_dict, result = test(model, val_dataset_dict, loss_func, is_show= is_show, only_Weaning = only_Weaning)\n",
    "            \n",
    "            train_loss_list.append(train_loss)\n",
    "            val_loss_list.append(result['total_loss'])\n",
    "            auc_list.append(result['total_auc'])\n",
    "            \n",
    "            ########################################################################################################################\n",
    "            for task_name in task_name_list:\n",
    "                if task_name not in local_best_model_dict:\n",
    "                    model_dict = {}\n",
    "                    model_dict['model'] = model.state_dict().copy()\n",
    "                    model_dict['performance'] = val_score_dict[task_name]\n",
    "                    model_dict['id'] = count\n",
    "                    local_best_model_dict[task_name] = model_dict\n",
    "                else:\n",
    "                    target_score = val_score_dict[task_name]\n",
    "                    if local_indicator == 'auroc':\n",
    "                        if local_best_model_dict[task_name]['performance'][local_indicator] < target_score[local_indicator] :\n",
    "                            local_best_model_dict[task_name]['performance'] = target_score\n",
    "                            local_best_model_dict[task_name]['model'] = model.state_dict().copy()\n",
    "                            local_best_model_dict[task_name]['id'] = count                           \n",
    "                    else:\n",
    "                        if local_best_model_dict[task_name]['performance'][local_indicator] > target_score[local_indicator] :\n",
    "                            local_best_model_dict[task_name]['performance'] = target_score\n",
    "                            local_best_model_dict[task_name]['model'] = model.state_dict().copy()\n",
    "                            local_best_model_dict[task_name]['id'] = count\n",
    "                    \n",
    "            for task_name in task_name_list:\n",
    "                if task_name not in best_model_dict:\n",
    "                    model_dict = {}\n",
    "                    model_dict['model'] = model.state_dict().copy()\n",
    "                    model_dict['performance'] = val_score_dict[task_name]\n",
    "                    model_dict['id'] = count\n",
    "                    best_model_dict[task_name] = model_dict\n",
    "                else:\n",
    "                    target_score = val_score_dict[task_name]\n",
    "                    if local_indicator == 'auroc':\n",
    "                        if best_model_dict[task_name]['performance'][local_indicator] < target_score[local_indicator] :\n",
    "                            best_model_dict[task_name]['performance'] = target_score\n",
    "                            best_model_dict[task_name]['model'] = model.state_dict().copy()\n",
    "                            best_model_dict[task_name]['id'] = count\n",
    "                    else:\n",
    "                        if best_model_dict[task_name]['performance'][local_indicator] > target_score[local_indicator] :\n",
    "                            best_model_dict[task_name]['performance'] = target_score\n",
    "                            best_model_dict[task_name]['model'] = model.state_dict().copy()\n",
    "                            best_model_dict[task_name]['id'] = count\n",
    "            count+=1\n",
    "\n",
    "            ########################################################################################################################\n",
    "            \"\"\" Early stop \"\"\"\n",
    "            if global_indicator == 'loss':\n",
    "                if result['total_loss'] < local_best_loss:\n",
    "                    local_best_loss = result['total_loss']\n",
    "                    if local_best_loss < global_best_loss:\n",
    "                        global_best_loss = local_best_loss\n",
    "                        best_model_params = model.state_dict().copy() \n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1     \n",
    "            else:\n",
    "                if result['total_auc'] > local_best_AUC:\n",
    "                    local_best_AUC = result['total_auc']\n",
    "                    if local_best_AUC > global_best_AUC:\n",
    "                        global_best_AUC = local_best_AUC\n",
    "                        best_model_params = model.state_dict().copy()\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1 \n",
    "            \n",
    "            global limit_early_stop_count\n",
    "            if patience_counter >= limit_early_stop_count:\n",
    "                break\n",
    "        \n",
    "        #is_show = True\n",
    "        empty_model = MLP_MTL(input_dim, task_name_list).to(device)\n",
    "        test_score_dict, result = test2(local_best_model_dict, empty_model, test_dataset_dict, loss_func, is_show = is_show)\n",
    "        ########################################################################################################################\n",
    "        #input()\n",
    "        for task_name in task_name_list:\n",
    "            test_score_dict[task_name]['time'] = time + 1\n",
    "            df_grade = pd.concat([df_grade, pd.DataFrame.from_records([test_score_dict[task_name]])])\n",
    "        print(df_grade)\n",
    "        print('----------finished----------')\n",
    "    \n",
    "    \n",
    "    global_stl_model_dict = {}\n",
    "    for task_name in task_name_list:\n",
    "        model = MLP_MTL(input_dim, task_name_list).to(device)\n",
    "        model.load_state_dict(best_model_dict[task_name]['model'])\n",
    "        local_stl_model_dict = MTL_to_STL(model)\n",
    "        global_stl_model_dict[task_name] = local_stl_model_dict[task_name]\n",
    "    \n",
    "    return df_grade, global_stl_model_dict, best_model_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be71fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "Input:\n",
    "    shap_value: flatten的結果,[sample,feature]\n",
    "    feature_name_list: flatten的feature list\n",
    "Output:\n",
    "    feature_important \n",
    "    sum_per_feature \n",
    "\"\"\"\n",
    "def calculate_feature_important(shap_value,feature_name_list):\n",
    "    abs_shap_value = np.abs(shap_value)\n",
    "    sum_per_feature = np.sum(abs_shap_value, axis=0)\n",
    "    sorted_feature_indices = np.argsort(sum_per_feature)[::-1] #[::-1]是reversed\n",
    "    sorted_feature_names = [feature_name_list[i] for i in sorted_feature_indices]\n",
    "    return sorted_feature_names, sum_per_feature\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "    model  \n",
    "    train_X (np)\n",
    "    test_X  (np)\n",
    "    test_X_original (np)\n",
    "    feature_name_list (list)\n",
    "    task_name (string)\n",
    "Output:\n",
    "    shap_value\n",
    "    shap_data\n",
    "    (flatten的結果)\n",
    "\"\"\"\n",
    "def get_model_shap(model,data_X_train,data_X_test,data_X_test_original,feature_name_list,task_name,use_mini_sample = True,n_sample = 100):\n",
    "    \n",
    "    max_sample = 1000\n",
    "    seq_day = data_X_train.shape[1]\n",
    "    feature_count = data_X_train.shape[2]\n",
    "    \n",
    "    if use_mini_sample:\n",
    "        background_data = torch.from_numpy(data_X_train[:max_sample]).float().to(device)\n",
    "        shap_data = torch.from_numpy(data_X_test[:max_sample]).float().to(device)\n",
    "        shap_data_original = torch.from_numpy(data_X_test_original[:max_sample]).float().to(device)\n",
    "    else:\n",
    "        background_data = torch.from_numpy(data_X_train[:]).float().to(device)\n",
    "        shap_data = torch.from_numpy(data_X_test[:]).float().to(device)\n",
    "        shap_data_original = torch.from_numpy(data_X_test_original[:]).float().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    explainer = shap.GradientExplainer(model, background_data)\n",
    "    \n",
    "    shap_values = explainer.shap_values(shap_data,nsamples=n_sample)\n",
    "    shap_values = np.array(shap_values)\n",
    "    \n",
    "    shap_value_flatten = np.zeros((len(shap_data),seq_day*feature_count))\n",
    "    shap_data_flatten = np.zeros((len(shap_data),seq_day*feature_count))\n",
    "    \n",
    "    for i in range(0,len(shap_data)):\n",
    "        count=0\n",
    "        for j in range(feature_count):\n",
    "            for k in range(seq_day):\n",
    "                shap_value_flatten[i][count]=shap_values[i][k][j]  \n",
    "                shap_data_flatten[i][count]=shap_data_original[i][k][j]  \n",
    "                count += 1\n",
    "    feature_important,_ = calculate_feature_important(shap_value_flatten, feature_name_list)\n",
    "    return feature_important, shap_value_flatten, shap_data_flatten\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "    shap_value_flatten (sample,feature_flatten)\n",
    "    shap_data_flatten (sample,feature_flatten)\n",
    "    max_display \n",
    "\"\"\"\n",
    "def show_shap(shap_value_flatten, shap_data_flatten,feature_name_list, max_display = 20,task_name = ''):\n",
    "    fig = shap.summary_plot(shap_value_flatten,shap_data_flatten,feature_names=feature_name_list, show=False,max_display = max_display)\n",
    "    plt.title(f\"***Task:{task_name}***\")\n",
    "    ax = plt.gca()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31150f",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8a8e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feature_list = []\n",
    "\n",
    "if use_mini_feature:\n",
    "    df_select_feature = pd.read_csv('./data/sample/select_feature.csv')\n",
    "    print(df_select_feature)\n",
    "    select_feature_list = df_select_feature['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "041cbcbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> input_dim: 101\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  1%|▊                                                                                 | 1/100 [00:01<02:25,  1.47s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  2%|█▋                                                                                | 2/100 [00:02<02:18,  1.41s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      " 21%|█████████████████                                                                | 21/100 [00:30<01:53,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: Weaning_successful \n",
      "{'task': 'Weaning_successful', 'auroc': 0.78, 'acc': 0.728, 'f1': 0.395, 'pre': 0.582, 'recall': 0.299, 'brier_score': 0.177, 'loss': 0.0003531794167227215}\n",
      "task: SBT_start \n",
      "{'task': 'SBT_start', 'auroc': 0.792, 'acc': 0.73, 'f1': 0.618, 'pre': 0.681, 'recall': 0.566, 'brier_score': 0.183, 'loss': 0.00026047491345414984}\n",
      "task: SBT_successful \n",
      "{'task': 'SBT_successful', 'auroc': 0.782, 'acc': 0.734, 'f1': 0.557, 'pre': 0.697, 'recall': 0.464, 'brier_score': 0.182, 'loss': 0.0002686673366807596}\n",
      "  time                task  auroc    acc     f1    pre  recall  brier_score  \\\n",
      "0    1  Weaning_successful  0.823  0.778  0.649  0.597   0.712        0.168   \n",
      "0    1           SBT_start  0.817  0.753  0.672  0.749   0.610        0.179   \n",
      "0    1      SBT_successful  0.818  0.761  0.643  0.759   0.557        0.174   \n",
      "\n",
      "       loss  \n",
      "0  0.000332  \n",
      "0  0.000259  \n",
      "0  0.000258  \n",
      "----------finished----------\n",
      "input dim:101 ==> 50.....\n",
      "==> input_dim: 50\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  1%|▊                                                                                 | 1/100 [00:01<02:19,  1.41s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  2%|█▋                                                                                | 2/100 [00:02<02:14,  1.38s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      " 36%|█████████████████████████████▏                                                   | 36/100 [00:50<01:29,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: Weaning_successful \n",
      "{'task': 'Weaning_successful', 'auroc': 0.784, 'acc': 0.719, 'f1': 0.526, 'pre': 0.528, 'recall': 0.523, 'brier_score': 0.174, 'loss': 0.00035349068542321523}\n",
      "task: SBT_start \n",
      "{'task': 'SBT_start', 'auroc': 0.805, 'acc': 0.724, 'f1': 0.6, 'pre': 0.682, 'recall': 0.536, 'brier_score': 0.178, 'loss': 0.00025432490738185905}\n",
      "task: SBT_successful \n",
      "{'task': 'SBT_successful', 'auroc': 0.804, 'acc': 0.732, 'f1': 0.578, 'pre': 0.669, 'recall': 0.508, 'brier_score': 0.175, 'loss': 0.0002576914471639714}\n",
      "  time                task  auroc    acc     f1    pre  recall  brier_score  \\\n",
      "0    1  Weaning_successful  0.836  0.781  0.573  0.654   0.510        0.155   \n",
      "0    1           SBT_start  0.816  0.736  0.608  0.788   0.495        0.178   \n",
      "0    1      SBT_successful  0.822  0.733  0.555  0.776   0.432        0.174   \n",
      "\n",
      "       loss  \n",
      "0  0.000313  \n",
      "0  0.000267  \n",
      "0  0.000265  \n",
      "----------finished----------\n",
      "input dim:50 ==> 25.....\n",
      "==> input_dim: 25\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  1%|▊                                                                                 | 1/100 [00:01<02:15,  1.37s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  2%|█▋                                                                                | 2/100 [00:02<02:12,  1.35s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      " 34%|███████████████████████████▌                                                     | 34/100 [00:47<01:32,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: Weaning_successful \n",
      "{'task': 'Weaning_successful', 'auroc': 0.781, 'acc': 0.703, 'f1': 0.0, 'pre': 0.0, 'recall': 0.0, 'brier_score': 0.201, 'loss': 0.00039021517667505476}\n",
      "task: SBT_start \n",
      "{'task': 'SBT_start', 'auroc': 0.804, 'acc': 0.72, 'f1': 0.628, 'pre': 0.645, 'recall': 0.612, 'brier_score': 0.181, 'loss': 0.00025534476989354845}\n",
      "task: SBT_successful \n",
      "{'task': 'SBT_successful', 'auroc': 0.805, 'acc': 0.736, 'f1': 0.611, 'pre': 0.652, 'recall': 0.575, 'brier_score': 0.177, 'loss': 0.00025744028614320505}\n",
      "  time                task  auroc    acc     f1    pre  recall  brier_score  \\\n",
      "0    1  Weaning_successful  0.821  0.778  0.588  0.633   0.548        0.161   \n",
      "0    1           SBT_start  0.811  0.751  0.656  0.769   0.571        0.180   \n",
      "0    1      SBT_successful  0.819  0.763  0.649  0.757   0.568        0.174   \n",
      "\n",
      "       loss  \n",
      "0  0.000325  \n",
      "0  0.000261  \n",
      "0  0.000256  \n",
      "----------finished----------\n",
      "input dim:25 ==> 12.....\n",
      "==> input_dim: 12\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  1%|▊                                                                                 | 1/100 [00:01<02:20,  1.42s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      " 36%|█████████████████████████████▏                                                   | 36/100 [00:50<01:30,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: Weaning_successful \n",
      "{'task': 'Weaning_successful', 'auroc': 0.778, 'acc': 0.753, 'f1': 0.548, 'pre': 0.6, 'recall': 0.505, 'brier_score': 0.175, 'loss': 0.0003520715981721878}\n",
      "task: SBT_start \n",
      "{'task': 'SBT_start', 'auroc': 0.786, 'acc': 0.696, 'f1': 0.555, 'pre': 0.64, 'recall': 0.49, 'brier_score': 0.187, 'loss': 0.0002648349285595986}\n",
      "task: SBT_successful \n",
      "{'task': 'SBT_successful', 'auroc': 0.774, 'acc': 0.704, 'f1': 0.533, 'pre': 0.618, 'recall': 0.469, 'brier_score': 0.187, 'loss': 0.00027180809370228943}\n",
      "  time                task  auroc    acc     f1    pre  recall  brier_score  \\\n",
      "0    1  Weaning_successful  0.811  0.753  0.491  0.606   0.413        0.162   \n",
      "0    1           SBT_start  0.819  0.718  0.576  0.764   0.462        0.186   \n",
      "0    1      SBT_successful  0.811  0.723  0.558  0.725   0.453        0.184   \n",
      "\n",
      "       loss  \n",
      "0  0.000326  \n",
      "0  0.000264  \n",
      "0  0.000265  \n",
      "----------finished----------\n",
      "input dim:12 ==> 11.....\n",
      "==> input_dim: 11\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  1%|▊                                                                                 | 1/100 [00:01<02:10,  1.32s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  2%|█▋                                                                                | 2/100 [00:02<02:13,  1.36s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      " 33%|██████████████████████████▋                                                      | 33/100 [00:48<01:37,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: Weaning_successful \n",
      "{'task': 'Weaning_successful', 'auroc': 0.769, 'acc': 0.747, 'f1': 0.556, 'pre': 0.582, 'recall': 0.533, 'brier_score': 0.179, 'loss': 0.0003565832558605406}\n",
      "task: SBT_start \n",
      "{'task': 'SBT_start', 'auroc': 0.796, 'acc': 0.71, 'f1': 0.55, 'pre': 0.687, 'recall': 0.459, 'brier_score': 0.182, 'loss': 0.0002629880662970759}\n",
      "task: SBT_successful \n",
      "{'task': 'SBT_successful', 'auroc': 0.783, 'acc': 0.714, 'f1': 0.527, 'pre': 0.653, 'recall': 0.441, 'brier_score': 0.182, 'loss': 0.00026912558486524}\n",
      "  time                task  auroc    acc     f1    pre  recall  brier_score  \\\n",
      "0    1  Weaning_successful  0.812  0.767  0.576  0.606   0.548        0.169   \n",
      "0    1           SBT_start  0.816  0.718  0.583  0.752   0.476        0.185   \n",
      "0    1      SBT_successful  0.810  0.711  0.520  0.722   0.406        0.184   \n",
      "\n",
      "       loss  \n",
      "0  0.000331  \n",
      "0  0.000263  \n",
      "0  0.000271  \n",
      "----------finished----------\n",
      "input dim:11 ==> 10.....\n",
      "==> input_dim: 10\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  1%|▊                                                                                 | 1/100 [00:01<02:19,  1.41s/it]Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      " 11%|████████▉                                                                        | 11/100 [00:16<02:16,  1.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mTrain\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m df_grade, stl_model_dict, best_model_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mtask_name_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask_name_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mtrain_loader_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mval_dataset_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataset_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mtest_dataset_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataset_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_show\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m df_grade[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremove_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m remove_time_count\n\u001b[0;32m     37\u001b[0m full_result_dict[remove_time_count] \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[49], line 60\u001b[0m, in \u001b[0;36mtrain_and_test_model\u001b[1;34m(experiment_time, max_epoch, learning_rate, input_dim, task_name_list, train_loader_dict, val_dataset_dict, test_dataset_dict, device, is_show, load_parm)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_show:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Epoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m val_score_dict, result \u001b[38;5;241m=\u001b[39m test(model, val_dataset_dict, loss_func, is_show\u001b[38;5;241m=\u001b[39m is_show, only_Weaning \u001b[38;5;241m=\u001b[39m only_Weaning)\n\u001b[0;32m     63\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[42], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader_dict, criterion, optimizer)\u001b[0m\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m label \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 25\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[task_name]\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(prob, label)\n\u001b[0;32m     27\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[40], line 61\u001b[0m, in \u001b[0;36mMLP_MTL.predict_prob\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 61\u001b[0m     prob_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     64\u001b[0m         prob_dict_true \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[40], line 47\u001b[0m, in \u001b[0;36mMLP_MTL.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_tasks):\n\u001b[0;32m     46\u001b[0m     task_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name_list[task_index]\n\u001b[1;32m---> 47\u001b[0m     hi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_fc0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     hi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(hi)\n\u001b[0;32m     49\u001b[0m     hi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hi)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x590 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#select_feature_list = []\n",
    "top_percent = 0.9\n",
    "remove_time_count = 0\n",
    "full_result_dict = {}\n",
    "featurn_count_list = []\n",
    "\n",
    "\n",
    "while len(select_feature_list)==0 or len(select_feature_list) > 5:\n",
    "    ########################################################################################################################\n",
    "    remove_time_count += 1\n",
    "    \"\"\"\n",
    "    read data\n",
    "    \"\"\"\n",
    "    train_dataset_dict,train_loader_dict,feature_name_list = read_data(task_name_list,'','train',select_feature_list,batch_size = batch_size,use_upsample = use_upsample)\n",
    "    val_dataset_dict,val_loader_dict,_ = read_data(task_name_list,'','validation',select_feature_list,batch_size = batch_size,use_upsample = use_upsample)\n",
    "    test_dataset_dict,test_loader_dict,_ = read_data(task_name_list,'','test',select_feature_list,batch_size = batch_size,use_upsample = use_upsample)\n",
    "    if len(select_feature_list)!=0:\n",
    "        feature_name_list = select_feature_list\n",
    "    input_dim = train_dataset_dict[task_name_list[0]].inputs.numpy().shape[2]\n",
    "    print(f'==> input_dim: {input_dim}')\n",
    "    featurn_count_list.append(input_dim)\n",
    "    ########################################################################################################################\n",
    "    \"\"\"\n",
    "    Train\n",
    "    \"\"\"\n",
    "    print(\"training\")\n",
    "    df_grade, stl_model_dict, best_model_dict = train_and_test_model(experiment_time = experiment_time, \n",
    "                                                     max_epoch = max_epoch, \n",
    "                                                     learning_rate = learning_rate, \n",
    "                                                     input_dim = input_dim, \n",
    "                                                     task_name_list = task_name_list, \n",
    "                                                     train_loader_dict = train_loader_dict, \n",
    "                                                     val_dataset_dict = val_dataset_dict, \n",
    "                                                     test_dataset_dict = test_dataset_dict, \n",
    "                                                     device = device, is_show = False)\n",
    "    df_grade['remove_time'] = remove_time_count\n",
    "    full_result_dict[remove_time_count] = {}\n",
    "    full_result_dict[remove_time_count]['result'] = df_grade\n",
    "    full_result_dict[remove_time_count]['model'] = stl_model_dict\n",
    "    full_result_dict[remove_time_count]['select_feature_list'] = feature_name_list\n",
    "    \n",
    "    if calculate_shap == False:\n",
    "        break\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \"\"\"\n",
    "    Shap\n",
    "    \"\"\"\n",
    "    shap_dict = {}\n",
    "    seq_day = 1\n",
    "    feature_count = len(feature_name_list)\n",
    "    sum_shap_value = np.zeros((0, seq_day * feature_count))\n",
    "    sum_shap_data = np.zeros((0, seq_day * feature_count))\n",
    "    #計算各任務的feature_important\n",
    "    for task_name in task_name_list:\n",
    "        shap_dict[task_name] = {}\n",
    "        feature_important, shap_value_flatten, shap_data_flatten = get_model_shap(\n",
    "                                                                    stl_model_dict[task_name],\n",
    "                                                                    train_dataset_dict[task_name].inputs.numpy(),\n",
    "                                                                    test_dataset_dict[task_name].inputs.numpy(),\n",
    "                                                                    test_dataset_dict[task_name].inputs_original.numpy(),\n",
    "                                                                    feature_name_list,\n",
    "                                                                    task_name,\n",
    "                                                                    use_mini_sample = False,\n",
    "                                                                    n_sample = 1)\n",
    "        \n",
    "        shap_dict[task_name]['feature_important'] = feature_important\n",
    "        shap_dict[task_name]['shap_value'] = shap_value_flatten\n",
    "        shap_dict[task_name]['shap_data'] = shap_data_flatten\n",
    "        shap_dict[task_name]['feature_name_list'] = feature_name_list\n",
    "\n",
    "        sum_shap_value = np.vstack([sum_shap_value, shap_value_flatten])\n",
    "        sum_shap_data = np.vstack([sum_shap_data, shap_data_flatten]) \n",
    "\n",
    "    full_result_dict[remove_time_count]['shap_result'] = shap_dict\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \"\"\"\n",
    "    select feature\n",
    "    \"\"\"\n",
    "    global_feature_important, _ = calculate_feature_important(sum_shap_value, feature_name_list)\n",
    "    full_result_dict[remove_time_count]['global_feature_important'] = global_feature_important\n",
    "    \n",
    "    if select_feature_flag == False:\n",
    "        break\n",
    "        \n",
    "    shap.summary_plot(sum_shap_value,sum_shap_data,plot_type=\"bar\",feature_names=feature_name_list, show=False,max_display = 20)\n",
    "    \n",
    "    if len(global_feature_important) <= 20:\n",
    "        select_feature_list = global_feature_important[:len(global_feature_important)-1]\n",
    "    else:\n",
    "        num_selected_features = int(len(global_feature_important) * top_percent)\n",
    "        num_selected_features = max(1, num_selected_features)\n",
    "        select_feature_list = global_feature_important[:num_selected_features]\n",
    "        \n",
    "    print(f'input dim:{len(global_feature_important)} ==> {len(select_feature_list)}.....')\n",
    "\n",
    "    ########################################################################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce9a4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "max_length = 120\n",
    "\n",
    "#跑特徵篩選\n",
    "if select_feature_flag:\n",
    "    df_select_features = pd.DataFrame()\n",
    "    path = \"./model/select_feature_result/\"\n",
    "    for time in range(1,remove_time_count+1):\n",
    "        save_feature_name(full_result_dict[time]['select_feature_list'], path, f'feature_name_list_{time}')\n",
    "        for task_name in task_name_list:\n",
    "            model_parm = full_result_dict[time]['model'][task_name].state_dict()\n",
    "            torch.save(model_parm, f'{path}/{task_name}_{time}')\n",
    "#跑Overlap\n",
    "else:\n",
    "    if input(f'save?(y/n)') == 'y':\n",
    "        path = \"./overlap\"\n",
    "        if 'SBT_start' in task_name_list:\n",
    "            group_name = 'vent'\n",
    "        else:\n",
    "            group_name = 'mortality'\n",
    "        time = 1\n",
    "        save_feature_name(full_result_dict[time]['select_feature_list'], path, 'feature_name_list')\n",
    "        for task_name in task_name_list:\n",
    "            torch.save(model_parm, f'{path}/{task_name}_group_{group_name}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3df142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30357896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
