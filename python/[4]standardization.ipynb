{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a5ae729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abd1b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_name = 'Weaning'\n",
    "task2_name = 'Weaning_successful'\n",
    "task3_name = 'SBT_start'\n",
    "task4_name = 'SBT_successful'\n",
    "task5_name = 'Mortality_30d'\n",
    "task6_name = 'Mortality_60d'\n",
    "task7_name = 'Mortality_90d'\n",
    "task8_name = 'Vasopressor'\n",
    "\n",
    "task_list = [task1_name,task2_name,task3_name,task4_name,task5_name,task6_name,task7_name,task8_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9a5f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/sample\"\n",
    "\n",
    "all_task_data = {}\n",
    "\n",
    "for task_name in task_list:\n",
    "    \n",
    "    # read\n",
    "    train_X = np.load(f\"{data_path}/train_X_{task_name}.npy\", allow_pickle=True)\n",
    "    train_Y = np.load(f\"{data_path}/train_Y_{task_name}.npy\", allow_pickle=True)\n",
    "    validation_X = np.load(f\"{data_path}/validation_X_{task_name}.npy\", allow_pickle=True)\n",
    "    validation_Y = np.load(f\"{data_path}/validation_Y_{task_name}.npy\", allow_pickle=True)\n",
    "    test_X = np.load(f\"{data_path}/test_X_{task_name}.npy\", allow_pickle=True)\n",
    "    test_Y = np.load(f\"{data_path}/test_Y_{task_name}.npy\", allow_pickle=True)\n",
    "    \n",
    "    # last day\n",
    "    last_day = train_X.shape[1] - 1\n",
    "    train_X = train_X[:, last_day, :]\n",
    "    validation_X = validation_X[:, last_day, :]\n",
    "    test_X = test_X[:, last_day, :]\n",
    "\n",
    "    all_task_data[task_name] = {\n",
    "        'train': {'X': train_X[:,1:], 'X_with_id': train_X, 'Y': train_Y},\n",
    "        'validation': {'X': validation_X[:,1:], 'X_with_id': validation_X,'Y': validation_Y},\n",
    "        'test': {'X': test_X[:,1:], 'X_with_id': test_X, 'Y': test_Y}\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a91e55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47318, 101)\n"
     ]
    }
   ],
   "source": [
    "num_features = all_task_data[task_name]['train']['X'].shape[1]\n",
    "\n",
    "combined_train_X = np.empty((0, num_features))\n",
    "\n",
    "for task_name in task_list:\n",
    "    train_x = all_task_data[task_name]['train']['X']\n",
    "    combined_train_X = np.vstack((combined_train_X, train_x))\n",
    "\n",
    "print(combined_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73cdbbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47318, 100)\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_X[:,1:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72821514",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21427349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/scaler_model.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)).fit(combined_train_X[:,:])\n",
    "\n",
    "#保存轉換器\n",
    "joblib.dump(scaler, './data/scaler_model.joblib')\n",
    "#input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7ee7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data, scaler):\n",
    "    return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36bbc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in task_list:\n",
    "    # 對訓練集進行縮放\n",
    "    all_task_data[task_name]['train']['scalar_X'] = scale_data(all_task_data[task_name]['train']['X'][:,:], scaler)\n",
    "    \n",
    "    # 對驗證集進行縮放\n",
    "    all_task_data[task_name]['validation']['scalar_X'] = scale_data(all_task_data[task_name]['validation']['X'][:,:], scaler)\n",
    "    \n",
    "    # 對測試集進行縮放\n",
    "    all_task_data[task_name]['test']['scalar_X'] = scale_data(all_task_data[task_name]['test']['X'][:,:], scaler)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5866ecb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:Weaning => 1:1182(32.72%)   0:2430(67.28%)\n",
      "Task:Weaning_successful => 1:1122(31.16%)   0:2479(68.84%)\n",
      "Task:SBT_start => 1:1893(37.34%)   0:3177(62.66%)\n",
      "Task:SBT_successful => 1:1708(34.36%)   0:3263(65.64%)\n",
      "Task:Mortality_30d => 1:3411(32.43%)   0:7107(67.57%)\n",
      "Task:Mortality_60d => 1:4043(37.23%)   0:6817(62.77%)\n",
      "Task:Mortality_90d => 1:4361(39.53%)   0:6670(60.47%)\n",
      "Task:Vasopressor => 1:1925(20.29%)   0:7564(79.71%)\n"
     ]
    }
   ],
   "source": [
    "for task_name in task_list:\n",
    "    train_y = all_task_data[task_name]['train']['Y']\n",
    "    val_y = all_task_data[task_name]['validation']['Y']\n",
    "    test_y = all_task_data[task_name]['test']['Y']\n",
    "    \n",
    "    total = np.concatenate((train_y, val_y), axis=0)\n",
    "    total = np.concatenate((total, test_y), axis=0)\n",
    "    \n",
    "    one_count = np.count_nonzero(total == 1)\n",
    "    zero_count = np.count_nonzero(total == 0)\n",
    "    \n",
    "    print(f'Task:{task_name} => 1:{one_count}({round(one_count*100/(one_count+zero_count),2)}%)   0:{zero_count}({round(zero_count*100/(one_count+zero_count),2)}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536a416",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c3fb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './data/sample/standard_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3f4c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for task_name in task_list: #[Weaning、SBT、 ...]\n",
    "    for data_type in all_task_data[task_name].keys():  #train、validation、test\n",
    "        for data_name in all_task_data[task_name][data_type].keys():  #X、Y、scalar_X\n",
    "            file_name = f'{data_type}_{data_name}_{task_name}'\n",
    "            folder = os.path.join(save_path, file_name)\n",
    "            data = all_task_data[task_name][data_type][data_name]\n",
    "            \n",
    "            if data.ndim == 2:\n",
    "                data = data.reshape(data.shape[0], 1, data.shape[1])\n",
    "            np.save(f'{folder}.npy', data)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945cc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
